# Dockerfile for Python Processor (å»ºè­°ä½¿ç”¨ç¨ç«‹çš„ Dockerfile.processor)

# ä½¿ç”¨ PyTorch 2.9.1 with CUDA 12.8 (æ”¯æ´ RTX 50 ç³»åˆ— sm_120)
FROM pytorch/pytorch:2.9.1-cuda12.8-cudnn9-runtime

# è¨­å®šç’°å¢ƒè®Šæ•¸
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV HF_HOME=/root/.cache/huggingface
ENV MODEL_CACHE_DIR=/root/.cache/huggingface/hub

# å®‰è£å¿…è¦å¥—ä»¶
RUN apt-get update && apt-get install -y \
    libsndfile1 \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# å»ºç«‹å¿«å–ç›®éŒ„
RUN mkdir -p /root/.cache/huggingface/hub

# è¨­å®šå·¥ä½œç›®éŒ„
WORKDIR /app

# è¤‡è£½ requirements
COPY processor/requirements.txt .

# ğŸŒŸ é—œéµä¿®å¾©ï¼šå®‰è£ cuDNN 9.x ä¸¦å»ºç«‹ç¬¦è™Ÿé€£çµ
RUN pip install --no-cache-dir nvidia-cudnn-cu12==9.5.1.17 && \
    # æ‰¾åˆ° cuDNN å®‰è£ä½ç½®ä¸¦å»ºç«‹ç¬¦è™Ÿé€£çµ
    CUDNN_PATH=$(python -c "import nvidia.cudnn; print(nvidia.cudnn.__path__[0])") && \
    echo "cuDNN path: ${CUDNN_PATH}" && \
    ls -la ${CUDNN_PATH}/lib/ && \
    # å»ºç«‹ç¬¦è™Ÿé€£çµåˆ°ç³»çµ±è·¯å¾‘
    ln -sf ${CUDNN_PATH}/lib/libcudnn*.so* /usr/local/cuda/lib64/ 2>/dev/null || true

# ğŸŒŸ å®‰è£ faster-whisper å’Œå…¶ä»–ä¾è³´
RUN pip install --no-cache-dir \
    ctranslate2>=4.5.0 \
    faster-whisper>=1.1.0 \
    deep-translator>=1.11.4 \
    redis>=5.0.0 \
    numpy>=1.24.0

# ğŸŒŸ è¨­å®š LD_LIBRARY_PATHï¼ˆåŒ…å«æ‰€æœ‰å¯èƒ½çš„ cuDNN è·¯å¾‘ï¼‰
ENV LD_LIBRARY_PATH="/usr/local/cuda/lib64:/opt/conda/lib/python3.12/site-packages/nvidia/cudnn/lib:/opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib:${LD_LIBRARY_PATH}"

# è¤‡è£½ç¨‹å¼ç¢¼
COPY processor/processor.py .

# ğŸŒŸ å•Ÿå‹•æ™‚å‹•æ…‹è¨­å®š cuDNN è·¯å¾‘
CMD ["sh", "-c", "export LD_LIBRARY_PATH=$(python -c 'import nvidia.cudnn; print(nvidia.cudnn.__path__[0])')/lib:$LD_LIBRARY_PATH && python processor.py"]