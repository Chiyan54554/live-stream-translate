# Dockerfile for Python Processor (å»ºè­°ä½¿ç”¨ç¨ç«‹çš„ Dockerfile.processor)

# ğŸš€ ä½¿ç”¨ NVIDIA CUDA 12.8 åŸºç¤æ˜ åƒ (RTX 50 ç³»åˆ—æ”¯æ´)
FROM nvidia/cuda:12.8.0-cudnn-runtime-ubuntu22.04

# è¨­å®šç’°å¢ƒè®Šæ•¸
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    HF_HOME=/root/.cache/huggingface \
    MODEL_CACHE_DIR=/root/.cache/huggingface/hub \
    PIP_CACHE_DIR=/root/.cache/pip \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    # ğŸš€ CUDA ç›¸é—œ
    CUDA_HOME=/usr/local/cuda \
    PATH=/usr/local/cuda/bin:$PATH \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

# ğŸš€ å®‰è£ Python 3.11 å’Œå¿…è¦å¥—ä»¶
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.11 \
    python3.11-venv \
    python3-pip \
    libsndfile1 \
    ffmpeg \
    && ln -sf /usr/bin/python3.11 /usr/bin/python \
    && ln -sf /usr/bin/python3.11 /usr/bin/python3 \
    && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* \
    && mkdir -p /root/.cache/huggingface/hub /root/.cache/pip

# è¨­å®šå·¥ä½œç›®éŒ„
WORKDIR /app

# ============================================================
# ğŸš€ åˆ†å±¤å¿«å–ç­–ç•¥ï¼šå°‡å¥—ä»¶å®‰è£åˆ†æˆå¤šå€‹ç¨ç«‹å±¤
# åªæœ‰ç•¶è©²å±¤çš„ä¾è³´è®Šæ›´æ™‚æ‰æœƒé‡æ–°å»ºæ§‹
# ============================================================

# ğŸ“¦ ç¬¬ä¸€å±¤ï¼šå®‰è£ PyTorch + torchaudio (æœ€å¤§ï¼Œç´„ 2.5GBï¼Œå¾ˆå°‘è®Šæ›´)
RUN --mount=type=cache,target=/root/.cache/pip,sharing=locked \
    pip install --no-compile \
        torch==2.7.0 \
        torchaudio==2.7.0 \
        --index-url https://download.pytorch.org/whl/cu128

# ğŸ“¦ ç¬¬äºŒå±¤ï¼šå®‰è£ ASR æ ¸å¿ƒå¥—ä»¶ (ä¸­ç­‰å¤§å°ï¼Œè¼ƒå°‘è®Šæ›´)
RUN --mount=type=cache,target=/root/.cache/pip,sharing=locked \
    pip install --no-compile \
        faster-whisper>=1.0.0 \
        "stable-ts>=2.16.0,<2.20.0" \
        --extra-index-url https://download.pytorch.org/whl/cu128

# ğŸ“¦ ç¬¬ä¸‰å±¤ï¼šå®‰è£ Transformers ç›¸é—œ (ä¸­ç­‰å¤§å°)
RUN --mount=type=cache,target=/root/.cache/pip,sharing=locked \
    pip install --no-compile \
        transformers>=4.40.0 \
        accelerate>=0.30.0 \
        punctuators>=0.0.5

# è¤‡è£½ requirementsï¼ˆç”¨æ–¼å®‰è£å‰©é¤˜å¥—ä»¶ï¼‰
COPY processor/requirements.txt .

# ğŸ“¦ ç¬¬å››å±¤ï¼šå®‰è£å‰©é¤˜å°å‹å¥—ä»¶ (å¿«é€Ÿï¼Œå¯èƒ½è¼ƒå¸¸è®Šæ›´)
RUN --mount=type=cache,target=/root/.cache/pip,sharing=locked \
    pip install --no-compile -r requirements.txt \
        --extra-index-url https://download.pytorch.org/whl/cu128

# ğŸŒŸ å»ºç«‹ç¬¦è™Ÿé€£çµï¼Œè®“ CTranslate2 æ‰¾åˆ° cuDNN
RUN CUDNN_PATH=$(python -c "import nvidia.cudnn; print(nvidia.cudnn.__path__[0])")/lib && \
    mkdir -p /usr/local/lib/ctranslate2 && \
    ln -sf $CUDNN_PATH/libcudnn*.so* /usr/local/lib/ctranslate2/

# ğŸš€ åˆä½µ COPY æŒ‡ä»¤ï¼Œæ¸›å°‘å±¤æ•¸
COPY processor/__init__.py processor/config.py processor/text_utils.py \
     processor/translator.py processor/asr.py processor/main.py ./
COPY processor/mappings/ ./mappings/

# ğŸŒŸ å•Ÿå‹•æ™‚è¨­å®š LD_LIBRARY_PATHï¼Œè®“ CTranslate2 å„ªå…ˆä½¿ç”¨æˆ‘å€‘å®‰è£çš„ cuDNN
CMD ["sh", "-c", "export LD_LIBRARY_PATH=/usr/local/lib/ctranslate2:$(python -c 'import nvidia.cudnn; print(nvidia.cudnn.__path__[0])')/lib:$LD_LIBRARY_PATH && python -m main"]