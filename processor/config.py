"""
é…ç½®æ¨¡çµ„ - æ‰€æœ‰è¨­å®šåƒæ•¸
ğŸ¯ å„ªåŒ–ï¼šé å…ˆè¨ˆç®—å¸¸æ•¸ã€é¿å…é‡è¤‡é‹ç®—ã€ä½¿ç”¨ __slots__ æ¸›å°‘è¨˜æ†¶é«”
"""
import os
import sys

# === ç’°å¢ƒè®Šæ•¸è™•ç† ===
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"

# === éŸ³è¨Šåƒæ•¸ (é å…ˆè¨ˆç®—çš„æ•´æ•¸å¸¸æ•¸) ===
SAMPLE_RATE: int = 16000
BYTES_PER_SAMPLE: int = 2
SOURCE_LANG_CODE: str = "ja"
TARGET_LANG_CODE: str = "zh-TW"

# === ç·©è¡èˆ‡å“è³ªè¨­å®š (ä½¿ç”¨ float è€Œéè¨ˆç®—å¼) ===
BUFFER_DURATION_S: float = 5.0       # 5 ç§’ç·©è¡ï¼Œè®“ ASR æœ‰æ›´å¤šä¸Šä¸‹æ–‡
OVERLAP_DURATION_S: float = 1.5      # å¢åŠ é‡ç–Šç¢ºä¿èªå¥é€£è²«
MIN_AUDIO_ENERGY: float = 0.002      # è¼ƒä½é–€æª»ï¼Œæ•æ‰è¼•è²èªéŸ³

# ğŸ¯ é å…ˆè¨ˆç®—çš„ç·©è¡å€å¤§å° (é¿å…é‹è¡Œæ™‚ä¹˜æ³•)
BUFFER_SIZE_BYTES: int = int(BUFFER_DURATION_S * SAMPLE_RATE * BYTES_PER_SAMPLE)
OVERLAP_SIZE_BYTES: int = int(OVERLAP_DURATION_S * SAMPLE_RATE * BYTES_PER_SAMPLE)

# ğŸ¯ é è¨ˆç®—çš„èƒ½é‡é–¾å€¼å¹³æ–¹ï¼ˆé¿å… sqrtï¼‰
MIN_AUDIO_ENERGY_SQUARED: float = MIN_AUDIO_ENERGY ** 2

# === Redis è¨­å®š ===
REDIS_HOST: str = os.getenv('REDIS_HOST', 'redis')
REDIS_PORT: int = int(os.getenv('REDIS_PORT', 6379))
AUDIO_CHANNEL: str = "audio_feed"
TRANSLATION_CHANNEL: str = "translation_feed"

# === ASR æ¨¡å‹è¨­å®š ===
# - large-v3: æ¨™æº– faster-whisper ç©©å®šç‰ˆ
# - kotoba-tech/kotoba-whisper-v2.2: æ—¥æ–‡å„ªåŒ– Transformers ç‰ˆ (æœ€æ–°ï¼Œæ”¯æ´æ¨™é»)
# - kotoba-tech/kotoba-whisper-v2.1: æ—¥æ–‡å„ªåŒ– Transformers ç‰ˆ (å¹»è¦ºæ›´å°‘)
# - kotoba-tech/kotoba-whisper-v2.0-faster: æ—¥æ–‡å„ªåŒ– CTranslate2 ç‰ˆ (RTX 50 ç³»åˆ—å¯èƒ½ä¸ç›¸å®¹)
# âš ï¸ æ³¨æ„ï¼šv2.2 æ²’æœ‰æä¾› faster ç‰ˆæœ¬
ASR_MODEL_NAME: str = os.getenv('ASR_MODEL_NAME', 'kotoba-tech/kotoba-whisper-v2.2')
MODEL_CACHE_DIR: str = os.getenv('MODEL_CACHE_DIR', '/root/.cache/huggingface/hub')

# ğŸ¯ é å…ˆè¨ˆç®—çš„å¸ƒæ—å€¼ (é¿å…é‡è¤‡å­—ä¸²æŸ¥æ‰¾)
USE_KOTOBA_PIPELINE: bool = 'kotoba-whisper-v2.1' in ASR_MODEL_NAME or 'kotoba-whisper-v2.2' in ASR_MODEL_NAME

# === LLM ç¿»è­¯è¨­å®š (Ollama) ===
LLM_HOST: str = os.getenv('LLM_HOST', 'ollama')
LLM_PORT: str = os.getenv('LLM_PORT', '11434')
LLM_MODEL: str = os.getenv('LLM_MODEL', 'qwen3:8b')
# ğŸ¯ é å…ˆå»ºç«‹çš„ URL (é¿å…æ¯æ¬¡è«‹æ±‚æ™‚å­—ä¸²æ ¼å¼åŒ–)
LLM_API_URL: str = f"http://{LLM_HOST}:{LLM_PORT}/api/generate"
LLM_TIMEOUT: int = 10  # ç¿»è­¯è¶…æ™‚ç§’æ•¸

# === stable-ts èˆ‡ VAD è¨­å®š (ä½¿ç”¨ bool å’Œ float å¸¸æ•¸) ===
USE_STABLE_TS: bool = True
USE_VAD: bool = True
VAD_THRESHOLD: float = 0.40          # ç¨ä½é–¾å€¼ï¼Œæ¸›å°‘æ¼æª¢
SUPPRESS_SILENCE: bool = True
HALLUCINATION_SILENCE_TH: float = 1.5
AVG_PROB_THRESHOLD: float = -0.6     # æ›´åš´æ ¼çš„ç½®ä¿¡åº¦éæ¿¾
MAX_INSTANT_WORDS: float = 0.25      # æ›´åš´æ ¼éæ¿¾ç¬æ™‚è©å¹»è¦º
ONLY_VOICE_FREQ: bool = True         # èšç„¦äººè²é »ç‡ç¯„åœ

# === ç™¼å¸ƒæ§åˆ¶è¨­å®š ===
MIN_PUBLISH_INTERVAL: float = 0.5
SIMILARITY_THRESHOLD: float = 0.75

# ğŸ¯ é å…ˆå»ºç«‹çš„é…ç½®å­—ä¸² (ç”¨æ–¼ print_config)
_CONFIG_SEPARATOR: str = "=" * 50
_CONFIG_LINES: tuple = (
    f"ğŸ¯ ASR æ¨¡å‹: {ASR_MODEL_NAME}",
    f"ğŸ¯ ä½¿ç”¨ Kotoba Pipeline: {USE_KOTOBA_PIPELINE}",
    f"ğŸ¯ LLM ç¿»è­¯: {LLM_MODEL} @ {LLM_HOST}:{LLM_PORT}",
    f"ğŸ¯ stable-ts: {USE_STABLE_TS}, VAD: {USE_VAD}",
)


def print_config() -> None:
    """å°å‡ºç•¶å‰é…ç½® - ğŸ¯ ä½¿ç”¨é å»ºç«‹çš„å­—ä¸²æ¸›å°‘é‹è¡Œæ™‚æ ¼å¼åŒ–"""
    print(_CONFIG_SEPARATOR, file=sys.stderr, flush=True)
    for line in _CONFIG_LINES:
        print(line, file=sys.stderr, flush=True)
    print(_CONFIG_SEPARATOR, file=sys.stderr, flush=True)
