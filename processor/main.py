"""
Live Stream Translate - æ—¥æ–‡ç›´æ’­å³æ™‚ç¿»è­¯è™•ç†å™¨
ä¸»ç¨‹å¼å…¥å£
ğŸš€ å„ªåŒ–ç‰ˆï¼šé è¨ˆç®—å¸¸æ•¸ã€æ¸›å°‘é‡è¤‡é‹ç®—
"""
import sys
import json
import time
import asyncio
import base64
from datetime import datetime, timezone, timedelta
from collections import deque

import numpy as np
import redis.asyncio as aioredis
import aiohttp

from config import (
    REDIS_HOST, REDIS_PORT, AUDIO_CHANNEL, TRANSLATION_CHANNEL,
    SAMPLE_RATE, BYTES_PER_SAMPLE, SOURCE_LANG_CODE, TARGET_LANG_CODE,
    BUFFER_DURATION_S, OVERLAP_DURATION_S,
    MIN_PUBLISH_INTERVAL, SIMILARITY_THRESHOLD,
    USE_VAD, SUPPRESS_SILENCE,
    print_config
)
from asr import setup_environment, init_asr_model, whisper_asr
from translator import llm_translate, warmup_llm
from text_utils import (
    filter_text, calculate_similarity,
    extract_new_content, merge_incomplete_sentence
)


# ============================================================
# ğŸš€ é è¨ˆç®—å¸¸æ•¸ï¼ˆé¿å…æ¯æ¬¡è™•ç†é‡æ–°è¨ˆç®—ï¼‰
# ============================================================

# éŸ³è¨Šç·©è¡å€å¤§å°ï¼ˆå–®ä½ï¼šbytesï¼‰
TARGET_BUFFER_SIZE = int(BUFFER_DURATION_S * SAMPLE_RATE * BYTES_PER_SAMPLE)
OVERLAP_BUFFER_SIZE = int(OVERLAP_DURATION_S * SAMPLE_RATE * BYTES_PER_SAMPLE)

# é å»ºç«‹æ™‚å€ç‰©ä»¶ï¼ˆé¿å…æ¯æ¬¡å»ºç«‹ï¼‰
TZ_TAIPEI = timezone(timedelta(hours=8))

# é æ ¼å¼åŒ– duration å­—ä¸²
DURATION_STR = f"{BUFFER_DURATION_S:.3f}"


# === å…¨åŸŸç‹€æ…‹ ===
audio_buffer = b''
overlap_buffer = b''
last_transcription = ""
last_full_sentence = ""
pending_text = ""
last_publish_time = 0
recent_texts = deque(maxlen=15)
context_history = deque(maxlen=8)
pending_translation_task = None
aio_session: aiohttp.ClientSession = None


def is_duplicate_or_overlap(text: str) -> bool:
    """æª¢æŸ¥æ–‡å­—æ˜¯å¦èˆ‡æœ€è¿‘ç™¼å¸ƒçš„å…§å®¹é‡è¤‡æˆ–é«˜åº¦é‡ç–Š - å„ªåŒ–ç‰ˆ"""
    global recent_texts, last_transcription
    
    # æå‰è¿”å›ï¼šç©ºå­—ä¸²æˆ–å®Œå…¨ç›¸åŒ
    if not text or text == last_transcription:
        return True
    
    # å­å­—ä¸²æª¢æŸ¥ï¼ˆå…ˆæª¢æŸ¥è¼ƒçŸ­çš„ï¼‰
    text_len = len(text)
    last_len = len(last_transcription)
    
    if text_len <= last_len:
        if text in last_transcription:
            return True
    elif last_transcription in text:
        pass  # æ–°æ–‡å­—åŒ…å«èˆŠæ–‡å­—ï¼Œå¯èƒ½æ˜¯æ“´å±•ï¼Œä¸ç®—é‡è¤‡
    
    # ä½¿ç”¨ any() æå‰çµ‚æ­¢
    return any(
        calculate_similarity(text, recent) > SIMILARITY_THRESHOLD
        for recent in recent_texts
    )


async def process_audio_chunk(audio_data_b64: str, r):
    """è™•ç†éŸ³è¨Šå¡Šï¼Œä½¿ç”¨æ»‘å‹•è¦–çª—æ©Ÿåˆ¶ + ä¸¦è¡Œç¿»è­¯"""
    global audio_buffer, overlap_buffer, last_transcription, last_publish_time
    global recent_texts, pending_text, last_full_sentence, pending_translation_task
    global aio_session
    
    # å…ˆæª¢æŸ¥ä¸Šä¸€å€‹ç¿»è­¯ä»»å‹™æ˜¯å¦å®Œæˆ
    if pending_translation_task is not None:
        if pending_translation_task.done():
            try:
                result = pending_translation_task.result()
                if result:
                    await r.publish(TRANSLATION_CHANNEL, json.dumps(result, ensure_ascii=False))
            except Exception as e:
                print(f"ç¿»è­¯ä»»å‹™éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
            pending_translation_task = None
    
    # è§£ç¢¼éŸ³è¨Š
    raw_bytes = base64.b64decode(audio_data_b64)
    
    # æ¢å¾©é‡ç–Šæ©Ÿåˆ¶
    audio_buffer = overlap_buffer + audio_buffer + raw_bytes
    
    # ä½¿ç”¨é è¨ˆç®—çš„å¸¸æ•¸
    if len(audio_buffer) < TARGET_BUFFER_SIZE:
        return
    
    # å–å‡ºè™•ç†çš„éŸ³è¨Š
    audio_to_process = audio_buffer[:TARGET_BUFFER_SIZE]
    
    # ä¿ç•™é‡ç–Šéƒ¨åˆ†
    overlap_buffer = audio_buffer[TARGET_BUFFER_SIZE - OVERLAP_BUFFER_SIZE:TARGET_BUFFER_SIZE]
    audio_buffer = audio_buffer[TARGET_BUFFER_SIZE:]
    
    # è½‰æ›ç‚º numpy array
    audio_array = np.frombuffer(audio_to_process, dtype=np.int16).astype(np.float32) / 32768.0
    
    # ASR è½‰éŒ„
    loop = asyncio.get_event_loop()
    text = await loop.run_in_executor(None, whisper_asr, audio_array)
    text = filter_text(text)
    
    if not text:
        return
    
    # æª¢æŸ¥æ˜¯å¦èˆ‡æœ€è¿‘å…§å®¹é‡è¤‡
    if is_duplicate_or_overlap(text):
        return
    
    # æå–æ–°å…§å®¹
    text = extract_new_content(text, last_transcription)
    if not text or len(text) < 2:
        return
    
    # å¥å­å®Œæ•´æ€§è™•ç†
    complete_sentence, pending_text = merge_incomplete_sentence(pending_text, text)
    
    # å¦‚æœæ²’æœ‰å®Œæ•´å¥å­ï¼Œç­‰å¾…æ›´å¤šè³‡æ–™
    if not complete_sentence:
        if len(pending_text) >= 30:
            complete_sentence = pending_text
            pending_text = ""
        else:
            return
    
    # æª¢æŸ¥ç™¼å¸ƒé–“éš”
    current_time = time.time()
    if current_time - last_publish_time < MIN_PUBLISH_INTERVAL:
        pending_text = complete_sentence + pending_text
        return
    
    # æ›´æ–°ç‹€æ…‹
    last_transcription = complete_sentence
    last_full_sentence = complete_sentence
    last_publish_time = current_time
    recent_texts.append(complete_sentence)
    context_history.append(complete_sentence)
    
    # ä¸¦è¡Œç¿»è­¯
    async def translate_and_prepare_result(text_to_translate: str):
        """ç¿»è­¯ä¸¦æº–å‚™çµæœ - å„ªåŒ–ç‰ˆ"""
        translation = await llm_translate(text_to_translate, aio_session)
        
        # å¦‚æœç¿»è­¯ç‚ºç©ºï¼Œè¿”å› None ä¸ç™¼å¸ƒ
        if not translation or not translation.strip():
            return None
        
        # ä½¿ç”¨é å»ºç«‹çš„æ™‚å€å’Œå¸¸æ•¸
        return {
            "timestamp": datetime.now(TZ_TAIPEI).strftime("%H:%M:%S"),
            "source_lang": SOURCE_LANG_CODE,
            "target_lang": TARGET_LANG_CODE,
            "duration_s": DURATION_STR,
            "transcription": text_to_translate,
            "translation": translation
        }
    
    # å¦‚æœæœ‰æ­£åœ¨é€²è¡Œçš„ç¿»è­¯ï¼Œç­‰å¾…å®ƒå®Œæˆ
    if pending_translation_task is not None and not pending_translation_task.done():
        try:
            result = await pending_translation_task
            if result:
                await r.publish(TRANSLATION_CHANNEL, json.dumps(result, ensure_ascii=False))
        except Exception as e:
            print(f"ç¿»è­¯ä»»å‹™éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
    
    # å•Ÿå‹•æ–°çš„ç¿»è­¯ä»»å‹™
    pending_translation_task = asyncio.create_task(translate_and_prepare_result(complete_sentence))


async def main():
    """ä¸»å¾ªç’°"""
    global aio_session
    
    import concurrent.futures
    
    # è¨­å®šç’°å¢ƒ
    setup_environment()
    
    # å°å‡ºé…ç½®
    print_config()
    
    # å»ºç«‹ç•°æ­¥ HTTP sessionï¼ˆæå‰å»ºç«‹ï¼‰
    aio_session = aiohttp.ClientSession()
    
    # å»ºç«‹åŸ·è¡Œç·’æ± 
    executor = concurrent.futures.ThreadPoolExecutor(max_workers=1)
    
    # ä¸¦è¡Œåˆå§‹åŒ–ï¼šASR æ¨¡å‹è¼‰å…¥ + Redis é€£ç·š
    loop = asyncio.get_event_loop()
    
    # åœ¨èƒŒæ™¯åŸ·è¡Œ ASR åˆå§‹åŒ–
    asr_future = loop.run_in_executor(executor, init_asr_model)
    
    # åŒæ™‚é€£æ¥ Redis
    try:
        r = aioredis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0)
        await r.ping()
        print(f"âœ… Redis é€£ç·šæˆåŠŸ (ç•°æ­¥æ¨¡å¼)", file=sys.stderr, flush=True)
    except Exception as e:
        print(f"âŒ Redis é€£ç·šå¤±æ•—: {e}", file=sys.stderr, flush=True)
        await aio_session.close()
        sys.exit(1)
    
    # ç­‰å¾… ASR åˆå§‹åŒ–å®Œæˆ
    await asr_future
    executor.shutdown(wait=False)
    
    # ğŸš€ èƒŒæ™¯é ç†± LLMï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
    asyncio.create_task(warmup_llm())

    p = r.pubsub()
    await p.subscribe(AUDIO_CHANNEL)
    print(f"âœ… å·²è¨‚é–±: {AUDIO_CHANNEL}", file=sys.stderr, flush=True)
    print(f"ğŸ¯ stable-ts æ•´åˆæ¨¡å¼å·²å•Ÿç”¨ (ç•°æ­¥)", file=sys.stderr, flush=True)
    print(f"ğŸ¯ VAD: {USE_VAD}, éœéŸ³æŠ‘åˆ¶: {SUPPRESS_SILENCE}", file=sys.stderr, flush=True)

    try:
        # ç•°æ­¥è®€å–è¨Šæ¯
        async for msg in p.listen():
            if msg['type'] == 'message':
                data = msg['data']
                if isinstance(data, bytes):
                    data = data.decode('utf-8')
                await process_audio_chunk(data, r)
    except asyncio.CancelledError:
        print(f"ğŸ›‘ æ”¶åˆ°å–æ¶ˆä¿¡è™Ÿ", file=sys.stderr, flush=True)
    finally:
        # æ¸…ç†è³‡æº
        await p.unsubscribe(AUDIO_CHANNEL)
        await r.close()
        await aio_session.close()
        print(f"âœ… è³‡æºå·²æ¸…ç†", file=sys.stderr, flush=True)


def run():
    """ç¨‹å¼å…¥å£é»"""
    asyncio.run(main())


if __name__ == "__main__":
    run()
