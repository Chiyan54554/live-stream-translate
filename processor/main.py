"""
Live Stream Translate - æ—¥æ–‡ç›´æ’­å³æ™‚ç¿»è­¯è™•ç†å™¨
ä¸»ç¨‹å¼å…¥å£
ğŸš€ å„ªåŒ–ç‰ˆï¼šé è¨ˆç®—å¸¸æ•¸ã€æ¸›å°‘é‡è¤‡é‹ç®—
"""
import sys
import json
import time
import asyncio
import base64
from datetime import datetime, timezone, timedelta
from collections import deque
from typing import Any

from config import (
    REDIS_HOST, REDIS_PORT, AUDIO_CHANNEL, TRANSLATION_CHANNEL,
    SAMPLE_RATE, BYTES_PER_SAMPLE, SOURCE_LANG_CODE, TARGET_LANG_CODE,
    BUFFER_DURATION_S, OVERLAP_DURATION_S,
    MIN_PUBLISH_INTERVAL, SIMILARITY_THRESHOLD,
    USE_VAD, SUPPRESS_SILENCE,
    print_config
)

# å»¶é²è¼‰å…¥é‡é‡ç´šå‡½æ•¸ï¼ˆé¦–æ¬¡ä½¿ç”¨æ™‚æ‰è¼‰å…¥ï¼‰
_whisper_asr = None
_llm_translate = None
_filter_text = None
_calculate_similarity = None
_extract_new_content = None
_merge_incomplete_sentence = None


# ============================================================
# ğŸš€ é è¨ˆç®—å¸¸æ•¸ï¼ˆé¿å…æ¯æ¬¡è™•ç†é‡æ–°è¨ˆç®—ï¼‰
# ============================================================

# éŸ³è¨Šç·©è¡å€å¤§å°ï¼ˆå–®ä½ï¼šbytesï¼‰
TARGET_BUFFER_SIZE = int(BUFFER_DURATION_S * SAMPLE_RATE * BYTES_PER_SAMPLE)
OVERLAP_BUFFER_SIZE = int(OVERLAP_DURATION_S * SAMPLE_RATE * BYTES_PER_SAMPLE)

# é å»ºç«‹æ™‚å€ç‰©ä»¶ï¼ˆé¿å…æ¯æ¬¡å»ºç«‹ï¼‰
TZ_TAIPEI = timezone(timedelta(hours=8))

# é æ ¼å¼åŒ– duration å­—ä¸²
DURATION_STR = f"{BUFFER_DURATION_S:.3f}"


# === å…¨åŸŸç‹€æ…‹ ===
audio_buffer = b''
overlap_buffer = b''
last_transcription = ""
last_full_sentence = ""
pending_text = ""
last_publish_time = 0
recent_texts = deque(maxlen=15)
context_history = deque(maxlen=8)
pending_translation_task = None
aio_session: Any = None


def _lazy_imports():
    """è¼‰å…¥é‡å‹æ¨¡çµ„èˆ‡å‡½æ•¸ï¼ˆåƒ…é¦–æ¬¡å‘¼å«ï¼‰"""
    global _whisper_asr, _llm_translate, _filter_text, _calculate_similarity
    global _extract_new_content, _merge_incomplete_sentence

    if _whisper_asr is None:
        from asr import whisper_asr  # å»¶é²é¿å…å•Ÿå‹•é˜»å¡
        from translator import llm_translate
        from text_utils import (
            filter_text, calculate_similarity,
            extract_new_content, merge_incomplete_sentence
        )
        _whisper_asr = whisper_asr
        _llm_translate = llm_translate
        _filter_text = filter_text
        _calculate_similarity = calculate_similarity
        _extract_new_content = extract_new_content
        _merge_incomplete_sentence = merge_incomplete_sentence


def is_duplicate_or_overlap(text: str) -> bool:
    """æª¢æŸ¥æ–‡å­—æ˜¯å¦èˆ‡æœ€è¿‘ç™¼å¸ƒçš„å…§å®¹é‡è¤‡æˆ–é«˜åº¦é‡ç–Š - å„ªåŒ–ç‰ˆ"""
    global recent_texts, last_transcription
    if _calculate_similarity is None:
        _lazy_imports()
    
    # æå‰è¿”å›ï¼šç©ºå­—ä¸²æˆ–å®Œå…¨ç›¸åŒ
    if not text or text == last_transcription:
        return True
    
    # å­å­—ä¸²æª¢æŸ¥ï¼ˆå…ˆæª¢æŸ¥è¼ƒçŸ­çš„ï¼‰
    text_len = len(text)
    last_len = len(last_transcription)
    
    if text_len <= last_len:
        if text in last_transcription:
            return True
    elif last_transcription in text:
        pass  # æ–°æ–‡å­—åŒ…å«èˆŠæ–‡å­—ï¼Œå¯èƒ½æ˜¯æ“´å±•ï¼Œä¸ç®—é‡è¤‡
    
    # ä½¿ç”¨ any() æå‰çµ‚æ­¢
    return any(
        _calculate_similarity(text, recent) > SIMILARITY_THRESHOLD
        for recent in recent_texts
    )


async def process_audio_chunk(audio_data_b64: str, r):
    """è™•ç†éŸ³è¨Šå¡Šï¼Œä½¿ç”¨æ»‘å‹•è¦–çª—æ©Ÿåˆ¶ + ä¸¦è¡Œç¿»è­¯"""
    global audio_buffer, overlap_buffer, last_transcription, last_publish_time
    global recent_texts, pending_text, last_full_sentence, pending_translation_task
    global aio_session
    _lazy_imports()
    
    # å…ˆæª¢æŸ¥ä¸Šä¸€å€‹ç¿»è­¯ä»»å‹™æ˜¯å¦å®Œæˆ
    if pending_translation_task is not None:
        if pending_translation_task.done():
            try:
                result = pending_translation_task.result()
                if result:
                    await r.publish(TRANSLATION_CHANNEL, json.dumps(result, ensure_ascii=False))
            except Exception as e:
                print(f"ç¿»è­¯ä»»å‹™éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
            pending_translation_task = None
    
    # è§£ç¢¼éŸ³è¨Š
    raw_bytes = base64.b64decode(audio_data_b64)
    
    # æ¢å¾©é‡ç–Šæ©Ÿåˆ¶
    audio_buffer = overlap_buffer + audio_buffer + raw_bytes
    
    # ä½¿ç”¨é è¨ˆç®—çš„å¸¸æ•¸
    if len(audio_buffer) < TARGET_BUFFER_SIZE:
        return
    
    # å–å‡ºè™•ç†çš„éŸ³è¨Š
    audio_to_process = audio_buffer[:TARGET_BUFFER_SIZE]
    
    # ä¿ç•™é‡ç–Šéƒ¨åˆ†
    overlap_buffer = audio_buffer[TARGET_BUFFER_SIZE - OVERLAP_BUFFER_SIZE:TARGET_BUFFER_SIZE]
    audio_buffer = audio_buffer[TARGET_BUFFER_SIZE:]
    
    # è½‰æ›ç‚º numpy arrayï¼ˆå»¶é²åŒ¯å…¥ï¼Œé¿å…å•Ÿå‹•é˜»å¡ï¼‰
    import numpy as np
    audio_array = np.frombuffer(audio_to_process, dtype=np.int16).astype(np.float32, copy=False) / 32768.0
    
    # ASR è½‰éŒ„
    loop = asyncio.get_event_loop()
    text = await loop.run_in_executor(None, _whisper_asr, audio_array)
    text = _filter_text(text)
    
    if not text:
        return
    
    # æª¢æŸ¥æ˜¯å¦èˆ‡æœ€è¿‘å…§å®¹é‡è¤‡
    if is_duplicate_or_overlap(text):
        return
    
    # æå–æ–°å…§å®¹
    text = _extract_new_content(text, last_transcription)
    if not text or len(text) < 2:
        return
    
    # å¥å­å®Œæ•´æ€§è™•ç†
    complete_sentence, pending_text = _merge_incomplete_sentence(pending_text, text)
    
    # å¦‚æœæ²’æœ‰å®Œæ•´å¥å­ï¼Œç­‰å¾…æ›´å¤šè³‡æ–™
    if not complete_sentence:
        if len(pending_text) >= 30:
            complete_sentence = pending_text
            pending_text = ""
        else:
            return
    
    # æª¢æŸ¥ç™¼å¸ƒé–“éš”
    current_time = time.time()
    if current_time - last_publish_time < MIN_PUBLISH_INTERVAL:
        pending_text = complete_sentence + pending_text
        return
    
    # æ›´æ–°ç‹€æ…‹
    last_transcription = complete_sentence
    last_full_sentence = complete_sentence
    last_publish_time = current_time
    recent_texts.append(complete_sentence)
    context_history.append(complete_sentence)
    
    # ä¸¦è¡Œç¿»è­¯
    async def translate_and_prepare_result(text_to_translate: str):
        """ç¿»è­¯ä¸¦æº–å‚™çµæœ - å„ªåŒ–ç‰ˆ"""
        translation = await _llm_translate(text_to_translate, aio_session)
        
        # å¦‚æœç¿»è­¯ç‚ºç©ºï¼Œè¿”å› None ä¸ç™¼å¸ƒ
        if not translation or not translation.strip():
            return None
        
        # ä½¿ç”¨é å»ºç«‹çš„æ™‚å€å’Œå¸¸æ•¸
        return {
            "timestamp": datetime.now(TZ_TAIPEI).strftime("%H:%M:%S"),
            "source_lang": SOURCE_LANG_CODE,
            "target_lang": TARGET_LANG_CODE,
            "duration_s": DURATION_STR,
            "transcription": text_to_translate,
            "translation": translation
        }
    
    # å¦‚æœæœ‰æ­£åœ¨é€²è¡Œçš„ç¿»è­¯ï¼Œç­‰å¾…å®ƒå®Œæˆ
    if pending_translation_task is not None and not pending_translation_task.done():
        try:
            result = await pending_translation_task
            if result:
                await r.publish(TRANSLATION_CHANNEL, json.dumps(result, ensure_ascii=False))
        except Exception as e:
            print(f"ç¿»è­¯ä»»å‹™éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
    
    # å•Ÿå‹•æ–°çš„ç¿»è­¯ä»»å‹™
    pending_translation_task = asyncio.create_task(translate_and_prepare_result(complete_sentence))


async def main():
    """ä¸»å¾ªç’°"""
    global aio_session
    from translator import warmup_llm

    # å°å‡ºé…ç½®
    print_config()

    async def init_redis():
        import redis.asyncio as aioredis
        last_err = None
        for attempt in range(3):
            try:
                r = aioredis.Redis(
                    host=REDIS_HOST,
                    port=REDIS_PORT,
                    db=0,
                    socket_connect_timeout=8,
                    socket_timeout=8,
                )
                await r.ping()
                print(f"âœ… Redis é€£ç·šæˆåŠŸ", file=sys.stderr, flush=True)
                return r
            except Exception as e:
                last_err = e
                await asyncio.sleep(1 + attempt)
        raise last_err

    async def init_asr():
        from asr import setup_environment, init_asr_model
        setup_environment()
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, init_asr_model)

    async def init_http_session():
        import aiohttp
        connector = aiohttp.TCPConnector(limit=10, ttl_dns_cache=300)
        return aiohttp.ClientSession(connector=connector)

    try:
        results = await asyncio.gather(
            init_redis(),
            init_asr(),
            init_http_session(),
            return_exceptions=True,
        )

        if isinstance(results[0], Exception):
            raise results[0]
        if isinstance(results[1], Exception):
            raise results[1]
        if isinstance(results[2], Exception):
            raise results[2]

        r = results[0]
        aio_session = results[2]

    except Exception as e:
        if aio_session:
            try:
                await aio_session.close()
            except Exception:
                pass
        print(f"âŒ åˆå§‹åŒ–å¤±æ•—: {e}", file=sys.stderr, flush=True)
        sys.exit(1)

    # é å…ˆç¶å®šé‡å‹å‡½æ•¸ä¸¦èƒŒæ™¯é ç†± LLM
    _lazy_imports()
    asyncio.create_task(warmup_llm())

    p = r.pubsub()
    await p.subscribe(AUDIO_CHANNEL)
    print(f"âœ… å·²è¨‚é–±: {AUDIO_CHANNEL}", file=sys.stderr, flush=True)
    print(f"ğŸ¯ stable-ts æ•´åˆæ¨¡å¼å·²å•Ÿç”¨ (ç•°æ­¥)", file=sys.stderr, flush=True)
    print(f"ğŸ¯ VAD: {USE_VAD}, éœéŸ³æŠ‘åˆ¶: {SUPPRESS_SILENCE}", file=sys.stderr, flush=True)

    try:
        # ç•°æ­¥è®€å–è¨Šæ¯
        async for msg in p.listen():
            if msg['type'] == 'message':
                data = msg['data']
                if isinstance(data, bytes):
                    data = data.decode('utf-8')
                await process_audio_chunk(data, r)
    except asyncio.CancelledError:
        print(f"ğŸ›‘ æ”¶åˆ°å–æ¶ˆä¿¡è™Ÿ", file=sys.stderr, flush=True)
    finally:
        # æ¸…ç†è³‡æº
        await p.unsubscribe(AUDIO_CHANNEL)
        await r.close()
        await aio_session.close()
        print(f"âœ… è³‡æºå·²æ¸…ç†", file=sys.stderr, flush=True)


def run():
    """ç¨‹å¼å…¥å£é»"""
    asyncio.run(main())


if __name__ == "__main__":
    run()
