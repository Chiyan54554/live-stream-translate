"""
Live Stream Translate - æ—¥æ–‡ç›´æ’­å³æ™‚ç¿»è­¯è™•ç†å™¨
ä¸»ç¨‹å¼å…¥å£
"""
import sys
import json
import time
import asyncio
import base64
from datetime import datetime, timezone, timedelta
from collections import deque

import numpy as np
import redis.asyncio as aioredis
import aiohttp

from config import (
    REDIS_HOST, REDIS_PORT, AUDIO_CHANNEL, TRANSLATION_CHANNEL,
    SAMPLE_RATE, BYTES_PER_SAMPLE, SOURCE_LANG_CODE, TARGET_LANG_CODE,
    BUFFER_DURATION_S, OVERLAP_DURATION_S,
    MIN_PUBLISH_INTERVAL, SIMILARITY_THRESHOLD,
    USE_VAD, SUPPRESS_SILENCE,
    print_config
)
from asr import setup_environment, init_asr_model, whisper_asr
from translator import llm_translate
from text_utils import (
    filter_text, calculate_similarity,
    extract_new_content, merge_incomplete_sentence
)


# === å…¨åŸŸç‹€æ…‹ ===
audio_buffer = b''
overlap_buffer = b''
last_transcription = ""
last_full_sentence = ""
pending_text = ""
last_publish_time = 0
recent_texts = deque(maxlen=15)
context_history = deque(maxlen=8)
pending_translation_task = None
aio_session: aiohttp.ClientSession = None


def is_duplicate_or_overlap(text: str) -> bool:
    """æª¢æŸ¥æ–‡å­—æ˜¯å¦èˆ‡æœ€è¿‘ç™¼å¸ƒçš„å…§å®¹é‡è¤‡æˆ–é«˜åº¦é‡ç–Š"""
    global recent_texts, last_transcription
    
    if not text:
        return True
    
    if text == last_transcription:
        return True
    
    if text in last_transcription or last_transcription in text:
        if text in last_transcription:
            return True
    
    for recent in recent_texts:
        similarity = calculate_similarity(text, recent)
        if similarity > SIMILARITY_THRESHOLD:
            return True
    
    return False


async def process_audio_chunk(audio_data_b64: str, r):
    """è™•ç†éŸ³è¨Šå¡Šï¼Œä½¿ç”¨æ»‘å‹•è¦–çª—æ©Ÿåˆ¶ + ä¸¦è¡Œç¿»è­¯"""
    global audio_buffer, overlap_buffer, last_transcription, last_publish_time
    global recent_texts, pending_text, last_full_sentence, pending_translation_task
    global aio_session
    
    # å…ˆæª¢æŸ¥ä¸Šä¸€å€‹ç¿»è­¯ä»»å‹™æ˜¯å¦å®Œæˆ
    if pending_translation_task is not None:
        if pending_translation_task.done():
            try:
                result = pending_translation_task.result()
                if result:
                    await r.publish(TRANSLATION_CHANNEL, json.dumps(result, ensure_ascii=False))
            except Exception as e:
                print(f"ç¿»è­¯ä»»å‹™éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
            pending_translation_task = None
    
    # è§£ç¢¼éŸ³è¨Š
    raw_bytes = base64.b64decode(audio_data_b64)
    
    # æ¢å¾©é‡ç–Šæ©Ÿåˆ¶
    audio_buffer = overlap_buffer + audio_buffer + raw_bytes
    
    # è¨ˆç®—ç›®æ¨™å¤§å°
    target_size = int(BUFFER_DURATION_S * SAMPLE_RATE * BYTES_PER_SAMPLE)
    overlap_size = int(OVERLAP_DURATION_S * SAMPLE_RATE * BYTES_PER_SAMPLE)
    
    if len(audio_buffer) < target_size:
        return
    
    # å–å‡ºè™•ç†çš„éŸ³è¨Š
    audio_to_process = audio_buffer[:target_size]
    
    # ä¿ç•™é‡ç–Šéƒ¨åˆ†
    overlap_buffer = audio_buffer[target_size - overlap_size:target_size]
    audio_buffer = audio_buffer[target_size:]
    
    # è½‰æ›ç‚º numpy array
    audio_array = np.frombuffer(audio_to_process, dtype=np.int16).astype(np.float32) / 32768.0
    
    # ASR è½‰éŒ„
    loop = asyncio.get_event_loop()
    text = await loop.run_in_executor(None, whisper_asr, audio_array)
    text = filter_text(text)
    
    if not text:
        return
    
    # æª¢æŸ¥æ˜¯å¦èˆ‡æœ€è¿‘å…§å®¹é‡è¤‡
    if is_duplicate_or_overlap(text):
        return
    
    # æå–æ–°å…§å®¹
    text = extract_new_content(text, last_transcription)
    if not text or len(text) < 2:
        return
    
    # å¥å­å®Œæ•´æ€§è™•ç†
    complete_sentence, pending_text = merge_incomplete_sentence(pending_text, text)
    
    # å¦‚æœæ²’æœ‰å®Œæ•´å¥å­ï¼Œç­‰å¾…æ›´å¤šè³‡æ–™
    if not complete_sentence:
        if len(pending_text) >= 30:
            complete_sentence = pending_text
            pending_text = ""
        else:
            return
    
    # æª¢æŸ¥ç™¼å¸ƒé–“éš”
    current_time = time.time()
    if current_time - last_publish_time < MIN_PUBLISH_INTERVAL:
        pending_text = complete_sentence + pending_text
        return
    
    # æ›´æ–°ç‹€æ…‹
    last_transcription = complete_sentence
    last_full_sentence = complete_sentence
    last_publish_time = current_time
    recent_texts.append(complete_sentence)
    context_history.append(complete_sentence)
    
    # ä¸¦è¡Œç¿»è­¯
    async def translate_and_prepare_result(text_to_translate):
        """ç¿»è­¯ä¸¦æº–å‚™çµæœ"""
        translation = await llm_translate(text_to_translate, aio_session)
        tz = timezone(timedelta(hours=8))
        return {
            "timestamp": datetime.now(tz).strftime("%H:%M:%S"),
            "source_lang": SOURCE_LANG_CODE,
            "target_lang": TARGET_LANG_CODE,
            "duration_s": f"{BUFFER_DURATION_S:.3f}",
            "transcription": text_to_translate,
            "translation": translation
        }
    
    # å¦‚æœæœ‰æ­£åœ¨é€²è¡Œçš„ç¿»è­¯ï¼Œç­‰å¾…å®ƒå®Œæˆ
    if pending_translation_task is not None and not pending_translation_task.done():
        try:
            result = await pending_translation_task
            if result:
                await r.publish(TRANSLATION_CHANNEL, json.dumps(result, ensure_ascii=False))
        except Exception as e:
            print(f"ç¿»è­¯ä»»å‹™éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
    
    # å•Ÿå‹•æ–°çš„ç¿»è­¯ä»»å‹™
    pending_translation_task = asyncio.create_task(translate_and_prepare_result(complete_sentence))


async def main():
    """ä¸»å¾ªç’°"""
    global aio_session
    
    # è¨­å®šç’°å¢ƒ
    setup_environment()
    
    # å°å‡ºé…ç½®
    print_config()
    
    # åˆå§‹åŒ– ASR
    init_asr_model()
    
    # å»ºç«‹ç•°æ­¥ HTTP session
    aio_session = aiohttp.ClientSession()
    
    try:
        # ä½¿ç”¨ç•°æ­¥ Redis
        r = aioredis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0)
        await r.ping()
        print(f"âœ… Redis é€£ç·šæˆåŠŸ (ç•°æ­¥æ¨¡å¼)", file=sys.stderr, flush=True)
    except Exception as e:
        print(f"âŒ Redis é€£ç·šå¤±æ•—: {e}", file=sys.stderr, flush=True)
        await aio_session.close()
        sys.exit(1)

    p = r.pubsub()
    await p.subscribe(AUDIO_CHANNEL)
    print(f"âœ… å·²è¨‚é–±: {AUDIO_CHANNEL}", file=sys.stderr, flush=True)
    print(f"ğŸ¯ stable-ts æ•´åˆæ¨¡å¼å·²å•Ÿç”¨ (ç•°æ­¥)", file=sys.stderr, flush=True)
    print(f"ğŸ¯ VAD: {USE_VAD}, éœéŸ³æŠ‘åˆ¶: {SUPPRESS_SILENCE}", file=sys.stderr, flush=True)

    try:
        # ç•°æ­¥è®€å–è¨Šæ¯
        async for msg in p.listen():
            if msg['type'] == 'message':
                data = msg['data']
                if isinstance(data, bytes):
                    data = data.decode('utf-8')
                await process_audio_chunk(data, r)
    except asyncio.CancelledError:
        print(f"ğŸ›‘ æ”¶åˆ°å–æ¶ˆä¿¡è™Ÿ", file=sys.stderr, flush=True)
    finally:
        # æ¸…ç†è³‡æº
        await p.unsubscribe(AUDIO_CHANNEL)
        await r.close()
        await aio_session.close()
        print(f"âœ… è³‡æºå·²æ¸…ç†", file=sys.stderr, flush=True)


def run():
    """ç¨‹å¼å…¥å£é»"""
    asyncio.run(main())


if __name__ == "__main__":
    run()
