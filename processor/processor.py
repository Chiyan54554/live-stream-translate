import sys
import json
import time
import numpy as np
import redis
import os
import base64
import io

# å¼•å…¥ PyTorch ä»¥æª¢æŸ¥ CUDA å¯ç”¨æ€§ï¼Œä»¥åŠ Whisper å’Œ googletrans
try:
    import torch 
    import whisper 
    from googletrans import Translator
except ImportError:
    print("éŒ¯èª¤ï¼šé‹è¡Œæ­¤è…³æœ¬éœ€è¦å®‰è£ 'openai-whisper', 'torch', 'numpy', 'redis', å’Œ 'googletrans'ã€‚", file=sys.stderr, flush=True)
    sys.exit(1)


# --- é…ç½®åƒæ•¸ ---
SAMPLE_RATE = 16000           # FFmpeg æ‡‰è©²è¼¸å‡º 16kHz
BYTES_PER_SAMPLE = 2          # 16-bit PCM
SOURCE_LANG_CODE = "ja"       # Whisper/Googletrans æºèªè¨€ (æ—¥æ–‡)
TARGET_LANG_CODE = "zh-TW"       # Whisper/Googletrans ç›®æ¨™èªè¨€ (ä¸­æ–‡)

# Redis é…ç½® (å¾ç’°å¢ƒè®Šé‡è®€å–ï¼Œä¾› Docker Compose ä½¿ç”¨)
REDIS_HOST = os.getenv('REDIS_HOST', 'redis')
REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))

AUDIO_CHANNEL = "audio_feed"           # ğŸ“¢ è¨‚é–±éŸ³é »çš„é »é“
TRANSLATION_CHANNEL = "translation_feed" # ğŸ‘‚ ç™¼ä½ˆç¿»è­¯çµæœçš„é »é“

# å¾ç’°å¢ƒè®Šæ•¸è®€å–æ¨¡å‹åç¨±ï¼Œé»˜èªä½¿ç”¨ 'tiny'
ASR_MODEL_NAME = os.getenv('ASR_MODEL_NAME', 'tiny') 

# ç¢ºå®šè¦ä½¿ç”¨çš„è¨­å‚™ï¼šå¦‚æœ CUDA å¯ç”¨ï¼Œå‰‡ä½¿ç”¨ GPUï¼Œå¦å‰‡ä½¿ç”¨ CPU
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# å…¨å±€è³‡æº
asr_model = None
translator = None

# ----------------------------------------------------
# è³‡æºåˆå§‹åŒ–èˆ‡ ASR/MT å‡½æ•¸
# ----------------------------------------------------

def init_global_resources():
    """è¼‰å…¥ Whisper æ¨¡å‹å’Œåˆå§‹åŒ–ç¿»è­¯å™¨ã€‚"""
    global asr_model, translator
    
    print(f"Whisper å°‡ä½¿ç”¨çš„è¨­å‚™: {DEVICE}", file=sys.stderr, flush=True)

    # 1. åˆå§‹åŒ–ç¿»è­¯å™¨
    translator = Translator()

    # 2. è¼‰å…¥ Whisper æ¨¡å‹
    try:
        print(f"æ­£åœ¨è¼‰å…¥ Whisper ASR æ¨¡å‹: {ASR_MODEL_NAME}...", file=sys.stderr, flush=True)
        
        # é—œéµä¿®æ”¹: å°‡æ¨¡å‹è¼‰å…¥åˆ°ç¢ºå®šçš„ DEVICE ä¸Š
        asr_model = whisper.load_model(ASR_MODEL_NAME, device=DEVICE)
        
        print(f"Whisper æ¨¡å‹è¼‰å…¥æˆåŠŸä¸¦å·²ç§»å‹•åˆ° {DEVICE} ä¸Šã€‚", file=sys.stderr, flush=True)
    except Exception as e:
        print(f"è‡´å‘½éŒ¯èª¤ï¼šWhisper æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ PyTorch å’Œ GPU ä¾è³´é …: {e}", file=sys.stderr, flush=True)
        sys.exit(1)


def whisper_asr(audio_data_b64: str) -> str:
    """
    ä½¿ç”¨ Whisper æ¨¡å‹å°‡ Base64 éŸ³è¨Šæ•¸æ“šè½‰éŒ„ç‚ºæ–‡æœ¬ã€‚
    """
    if asr_model is None:
        return "éŒ¯èª¤: Whisper æ¨¡å‹å°šæœªè¼‰å…¥ã€‚"

    try:
        # 1. è§£ç¢¼ Base64 æ•¸æ“šç‚ºåŸå§‹ PCM æ•¸æ“š (bytes)
        raw_audio_bytes = base64.b64decode(audio_data_b64)
        
        # 2. å°‡åŸå§‹ 16-bit PCM æ•¸æ“šè½‰æ›ç‚º Whisper æ‰€éœ€çš„ float32 Numpy é™£åˆ—
        audio_array = np.frombuffer(raw_audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
        
        # 3. é—œéµä¿®æ”¹: å°‡ Numpy é™£åˆ—è½‰æ›ç‚º PyTorch Tensor ä¸¦ç§»å‹•åˆ°æ­£ç¢ºçš„ DEVICE
        audio_tensor = torch.from_numpy(audio_array).to(DEVICE)

        # 4. ä½¿ç”¨ Whisper è½‰éŒ„ (ç›´æ¥å‚³é Tensor)
        result = asr_model.transcribe(
            audio_tensor, # ä½¿ç”¨ PyTorch Tensor
            language=SOURCE_LANG_CODE,
            # å•Ÿç”¨ fp16 åŠ é€Ÿ GPU ä¸Šçš„æ¨è«–
            fp16=True if DEVICE == "cuda" else False, 
            verbose=False 
        )
        return result["text"].strip()

    except Exception as e:
        print(f"Whisper ASR è™•ç†å¤±æ•—: {e}", file=sys.stderr, flush=True)
        return "Whisper_ASR_FAILURE"


def google_mt(text: str) -> str:
    """
    ä½¿ç”¨ googletrans é€²è¡Œæ©Ÿå™¨ç¿»è­¯ã€‚
    """
    if not text or translator is None:
        return ""
    try:
        translation = translator.translate(
            text, 
            src=SOURCE_LANG_CODE, 
            dest=TARGET_LANG_CODE
        )
        return translation.text
    except Exception as e:
        print(f"ç¿»è­¯å¤±æ•— (googletrans error): {e}", file=sys.stderr, flush=True)
        return f"MT_FAILURE: {text}"

# ----------------------------------------------------
# æ ¸å¿ƒè™•ç†å‡½æ•¸ï¼šå¾ Redis æ¥æ”¶æ•¸æ“šï¼Œè™•ç†ï¼Œå†ç™¼ä½ˆåˆ° Redis
# ----------------------------------------------------

def process_audio_chunk(audio_data_b64, r):
    # åŸ·è¡Œå¯¦éš›çš„ Whisper ASR
    transcribed_text = whisper_asr(audio_data_b64)
    
    # åŸ·è¡Œå¯¦éš›ç¿»è­¯
    translated_text = google_mt(transcribed_text)
    
    duration_seconds = 0.128 
    timestamp = time.strftime("%H:%M:%S")
    
    result = {
        "timestamp": timestamp,
        "source_lang": SOURCE_LANG_CODE,
        "target_lang": TARGET_LANG_CODE,
        "duration_s": f"{duration_seconds:.3f}",
        "transcription": transcribed_text,
        "translation": translated_text
    }
    
    try:
        json_output = json.dumps(result, ensure_ascii=False)
        r.publish(TRANSLATION_CHANNEL, json_output) # ç™¼ä½ˆåˆ°ç¿»è­¯çµæœé »é“
    except Exception as e:
        print(f"è‡´å‘½éŒ¯èª¤ï¼šPython ç™¼ä½ˆç¿»è­¯çµæœåˆ° Redis å¤±æ•—: {e}", file=sys.stderr, flush=True)


def main():
    """
    ä¸»å¾ªç’°ï¼šè¨‚é–± Redis éŸ³é »é »é“ï¼Œä¸¦åˆå§‹åŒ–å…¨å±€è³‡æºã€‚
    """
    # è¼‰å…¥ Whisper æ¨¡å‹
    init_global_resources() 

    # 1. åˆå§‹åŒ– Redis å®¢æˆ¶ç«¯
    try:
        r = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0) 
        r.ping()
        print(f"Python æˆåŠŸé€£æ¥åˆ° Redis ({REDIS_HOST}:{REDIS_PORT})ã€‚", file=sys.stderr, flush=True)
    except Exception as e:
        print(f"è‡´å‘½éŒ¯èª¤ï¼šPython ç„¡æ³•é€£æ¥åˆ° Redis: {e}", file=sys.stderr, flush=True)
        sys.exit(1)

    # 2. è¨­ç½® Redis è¨‚é–±
    p = r.pubsub()
    p.subscribe(AUDIO_CHANNEL)
    print(f"Python æˆåŠŸè¨‚é–± Redis é »é“: {AUDIO_CHANNEL}ã€‚", file=sys.stderr, flush=True)

    # 3. ä¸»å¾ªç’°ï¼šå¾ Redis è¨‚é–±ä¸­è®€å–éŸ³é »æ•¸æ“š
    for message in p.listen():
        if message['type'] == 'message':
            audio_chunk_b64 = message['data'].decode('utf-8') 
            process_audio_chunk(audio_chunk_b64, r)
        elif message['type'] == 'subscribe':
             print(f"å·²æˆåŠŸè¨‚é–± {message['channel'].decode('utf-8')}", file=sys.stderr, flush=True)

if __name__ == "__main__":
    main()