import sys
import json
import time
from datetime import datetime, timezone, timedelta
import numpy as np
import redis
import os
import base64
import re
from concurrent.futures import ThreadPoolExecutor
from collections import deque

os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"

# ğŸŒŸ ç¢ºä¿ cuDNN è·¯å¾‘æ­£ç¢ºï¼ˆåœ¨ import torch ä¹‹å‰ï¼‰
try:
    import nvidia.cudnn
    cudnn_lib = os.path.join(nvidia.cudnn.__path__[0], "lib")
    current_ld = os.environ.get("LD_LIBRARY_PATH", "")
    if cudnn_lib not in current_ld:
        os.environ["LD_LIBRARY_PATH"] = f"{cudnn_lib}:{current_ld}"
    print(f"âœ… cuDNN è·¯å¾‘å·²è¨­å®š: {cudnn_lib}", file=sys.stderr, flush=True)
except ImportError:
    print("âš ï¸ nvidia-cudnn æœªå®‰è£", file=sys.stderr, flush=True)

try:
    import torch
    print(f"PyTorch: {torch.__version__}", file=sys.stderr, flush=True)
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}", file=sys.stderr, flush=True)
    if torch.cuda.is_available():
        print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}", file=sys.stderr, flush=True)
        print(f"GPU: {torch.cuda.get_device_name(0)}", file=sys.stderr, flush=True)
    
    from faster_whisper import WhisperModel
    from deep_translator import GoogleTranslator
except ImportError as e:
    print(f"éŒ¯èª¤ï¼š{e}", file=sys.stderr, flush=True)
    sys.exit(1)

# --- é…ç½®åƒæ•¸ ---
SAMPLE_RATE = 16000
BYTES_PER_SAMPLE = 2
SOURCE_LANG_CODE = "ja"
TARGET_LANG_CODE = "zh-TW"

BUFFER_DURATION_S = 5.0
OVERLAP_DURATION_S = 1.5
MIN_AUDIO_ENERGY = 0.006

REDIS_HOST = os.getenv('REDIS_HOST', 'redis')
REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))
AUDIO_CHANNEL = "audio_feed"
TRANSLATION_CHANNEL = "translation_feed"

ASR_MODEL_NAME = os.getenv('ASR_MODEL_NAME', 'large-v3')
MODEL_CACHE_DIR = os.getenv('MODEL_CACHE_DIR', '/root/.cache/huggingface/hub')

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
COMPUTE_TYPE = "float16" if DEVICE == "cuda" else "int8"

asr_model = None
translator = None
audio_buffer = b''
overlap_buffer = b''
last_transcription = ""
context_history = deque(maxlen=5)
executor = ThreadPoolExecutor(max_workers=2)

def init_global_resources():
    global asr_model, translator, DEVICE, COMPUTE_TYPE
    
    print(f"="*50, file=sys.stderr, flush=True)
    print(f"ğŸ¯ è¨­å‚™: {DEVICE}, è¨ˆç®—é¡å‹: {COMPUTE_TYPE}", file=sys.stderr, flush=True)
    print(f"ğŸ¯ æ¨¡å‹: {ASR_MODEL_NAME}", file=sys.stderr, flush=True)
    print(f"="*50, file=sys.stderr, flush=True)

    try:
        translator = GoogleTranslator(source=SOURCE_LANG_CODE, target=TARGET_LANG_CODE)
        print("âœ… ç¿»è­¯å¼•æ“å°±ç·’", file=sys.stderr, flush=True)
    except Exception as e:
        print(f"âŒ ç¿»è­¯å¼•æ“å¤±æ•—: {e}", file=sys.stderr, flush=True)
        sys.exit(1)

    def try_load_model(device, compute_type):
        try:
            print(f"ğŸ”„ è¼‰å…¥: {device}/{compute_type}...", file=sys.stderr, flush=True)
            model = WhisperModel(
                ASR_MODEL_NAME,
                device=device,
                compute_type=compute_type,
                download_root=MODEL_CACHE_DIR,
                cpu_threads=os.cpu_count() or 4,
                num_workers=2,
            )
            # é ç†±æ¸¬è©¦
            list(model.transcribe(np.zeros(16000, dtype=np.float32), language="ja"))
            return model
        except Exception as e:
            print(f"âš ï¸ {device}/{compute_type} å¤±æ•—: {e}", file=sys.stderr, flush=True)
            return None

    start = time.time()
    for device, ctype in [("cuda", "float16"), ("cuda", "int8_float16"), ("cpu", "int8")]:
        if device == "cuda" and not torch.cuda.is_available():
            continue
        asr_model = try_load_model(device, ctype)
        if asr_model:
            DEVICE, COMPUTE_TYPE = device, ctype
            break
    
    if not asr_model:
        print("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—", file=sys.stderr, flush=True)
        sys.exit(1)
    
    status = "ğŸš€ GPU" if DEVICE == "cuda" else "âš ï¸ CPU"
    print(f"âœ… {status} æ¨¡å¼: {DEVICE}/{COMPUTE_TYPE}, {time.time()-start:.1f}s", file=sys.stderr, flush=True)

def check_voice_activity(audio_array: np.ndarray) -> bool:
    """ç°¡å–®çš„èªéŸ³æ´»å‹•åµæ¸¬ (VAD)ã€‚"""
    rms = np.sqrt(np.mean(audio_array ** 2))
    return rms > MIN_AUDIO_ENERGY

def get_context_prompt() -> str:
    """ç”Ÿæˆä¸Šä¸‹æ–‡æç¤º"""
    if not context_history:
        return "ã“ã‚Œã¯æ—¥æœ¬èªã®ä¼šè©±ã§ã™ã€‚"
    recent = "ã€‚".join(list(context_history)[-3:])
    return f"ã“ã‚Œã¯æ—¥æœ¬èªã®ä¼šè©±ã§ã™ã€‚{recent}"

def whisper_asr(audio_array: np.ndarray) -> str:
    """ä½¿ç”¨ faster-whisper é€²è¡ŒèªéŸ³è¾¨è­˜ã€‚"""
    if asr_model is None or not check_voice_activity(audio_array):
        return ""

    try:
        segments, info = asr_model.transcribe(
            audio_array,
            language=SOURCE_LANG_CODE,
            
            # ğŸŒŸ æå‡æº–ç¢ºåº¦çš„åƒæ•¸
            beam_size=8,              # å¢åŠ æœç´¢å¯¬åº¦
            best_of=8,                # å¤šå€™é¸é¸æ“‡
            patience=2.0,             # å¢åŠ è€å¿ƒå€¼
            
            temperature=[0.0, 0.2, 0.4],  # å¤šæº«åº¦å›é€€
            compression_ratio_threshold=2.4,
            
            condition_on_previous_text=True,  # åˆ©ç”¨ä¸Šä¸‹æ–‡
            no_speech_threshold=0.5,
            log_prob_threshold=-0.8,
            
            initial_prompt=get_context_prompt(),
            
            # ğŸŒŸ VAD å„ªåŒ–
            vad_filter=True,
            vad_parameters=dict(
                threshold=0.4,
                min_speech_duration_ms=200,
                min_silence_duration_ms=400,
                speech_pad_ms=250,
            ),
            
            word_timestamps=True,
        )
        
        text_parts = []
        for seg in segments:
            # éæ¿¾ä½ç½®ä¿¡åº¦ç‰‡æ®µ
            if seg.avg_logprob > -0.9 and seg.no_speech_prob < 0.6:
                text_parts.append(seg.text)
        
        result = "".join(text_parts).strip()
        
        # æ›´æ–°ä¸Šä¸‹æ–‡
        if result and len(result) > 3:
            context_history.append(result)
        
        return result

    except Exception as e:
        print(f"ASR éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
        return ""

def google_mt(text: str) -> str:
    """ä½¿ç”¨ Deep Translator é€²è¡Œç¿»è­¯ã€‚"""
    if not text or not translator:
        return ""
    try:
        return translator.translate(text)
    except Exception as e:
        print(f"ç¿»è­¯éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
        return ""

def filter_text(text: str) -> str:
    """éæ¿¾ç„¡æ•ˆæ–‡å­—ã€‚"""
    if not text:
        return ""
    
    # æ—¥æ–‡å­—ç¬¦éæ¿¾
    pattern = re.compile(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF\uFF00-\uFFEF\u0020-\u007E]+')
    cleaned = "".join(pattern.findall(text)).strip()
    
    # ğŸŒŸ æ“´å±•éæ¿¾åˆ—è¡¨
    unwanted = [
        "[éŸ³å£°ãªã—]", "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†", "æœ€å¾Œã¾ã§ã”è¦–è´",
        "(æ‹æ‰‹)", "(ç¬‘ã„)", "(ãŸã‚æ¯)", "å­—å¹•",
        "ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²", "é«˜è©•ä¾¡", "MBSãƒ‹ãƒ¥ãƒ¼ã‚¹",
        "æä¾›ã¯", "ã”è¦§ã„ãŸã ã",
    ]
    
    for phrase in unwanted:
        if phrase in cleaned:
            return ""
    
    # æª¢æŸ¥é‡è¤‡å­—ç¬¦ï¼ˆå¹»è¦ºç‰¹å¾µï¼‰
    if len(cleaned) > 4:
        char_count = max(cleaned.count(c) for c in set(cleaned))
        if char_count > len(cleaned) * 0.5:
            return ""
    
    return cleaned if len(cleaned) >= 2 else ""

def remove_duplicate(current: str, previous: str) -> str:
    """ç§»é™¤èˆ‡ä¸Šä¸€æ¬¡è½‰éŒ„é‡è¤‡çš„éƒ¨åˆ†ã€‚"""
    if not previous or not current:
        return current
    if current == previous or current in previous:
        return ""
    
    # ğŸŒŸ æ”¹é€²é‡ç–Šæª¢æ¸¬
    if previous in current:
        idx = current.find(previous)
        if idx == 0:
            return current[len(previous):].strip()
    
    for i in range(min(len(previous), len(current)), 0, -1):
        if previous[-i:] == current[:i]:
            return current[i:].strip()
    
    return current

# ----------------------------------------------------
# æ ¸å¿ƒè™•ç†å‡½æ•¸
# ----------------------------------------------------

def process_audio_chunk(audio_data_b64: str, r):
    """è™•ç†éŸ³è¨Šå¡Šï¼Œä½¿ç”¨æ»‘å‹•è¦–çª—æ©Ÿåˆ¶ã€‚"""
    global audio_buffer, overlap_buffer, last_transcription
    
    # è§£ç¢¼éŸ³è¨Š
    raw_bytes = base64.b64decode(audio_data_b64)
    audio_buffer = overlap_buffer + audio_buffer + raw_bytes
    
    # è¨ˆç®—ç›®æ¨™å¤§å°
    target_size = int(BUFFER_DURATION_S * SAMPLE_RATE * BYTES_PER_SAMPLE)
    overlap_size = int(OVERLAP_DURATION_S * SAMPLE_RATE * BYTES_PER_SAMPLE)
    
    if len(audio_buffer) < target_size:
        return
    
    # å–å‡ºè™•ç†çš„éŸ³è¨Š
    audio_to_process = audio_buffer[:target_size]
    # ğŸŒŸ ä¿ç•™é‡ç–Šéƒ¨åˆ†ä¾›ä¸‹æ¬¡ä½¿ç”¨
    overlap_buffer = audio_buffer[target_size - overlap_size:target_size]
    audio_buffer = audio_buffer[target_size:]
    
    # è½‰æ›ç‚º numpy array
    audio_array = np.frombuffer(audio_to_process, dtype=np.int16).astype(np.float32) / 32768.0
    
    # ASR è½‰éŒ„
    text = whisper_asr(audio_array)
    # éæ¿¾æ–‡å­—
    text = filter_text(text)
    if not text:
        return
    
    # ğŸŒŸ å»é™¤é‡è¤‡
    text = remove_duplicate(text, last_transcription)
    if not text:
        return
    
    last_transcription = text
    
    # ğŸŒŸ ä¸¦è¡ŒåŸ·è¡Œç¿»è­¯
    future = executor.submit(google_mt, text)
    translation = future.result(timeout=5)
    
    # æ™‚é–“æˆ³
    tz = timezone(timedelta(hours=8))
    result = {
        "timestamp": datetime.now(tz).strftime("%H:%M:%S"),
        "source_lang": SOURCE_LANG_CODE,
        "target_lang": TARGET_LANG_CODE,
        "duration_s": f"{BUFFER_DURATION_S:.3f}",
        "transcription": text,
        "translation": translation
    }
    
    try:
        r.publish(TRANSLATION_CHANNEL, json.dumps(result, ensure_ascii=False))
    except Exception as e:
        print(f"ç™¼ä½ˆéŒ¯èª¤: {e}", file=sys.stderr, flush=True)

def main():
    """ä¸»å¾ªç’°ã€‚"""
    init_global_resources()

    try:
        r = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0)
        r.ping()
        print(f"âœ… Redis é€£ç·šæˆåŠŸ", file=sys.stderr, flush=True)
    except Exception as e:
        print(f"âŒ Redis é€£ç·šå¤±æ•—: {e}", file=sys.stderr, flush=True)
        sys.exit(1)

    p = r.pubsub()
    p.subscribe(AUDIO_CHANNEL)
    print(f"âœ… å·²è¨‚é–±: {AUDIO_CHANNEL}", file=sys.stderr, flush=True)

    for msg in p.listen():
        if msg['type'] == 'message':
            process_audio_chunk(msg['data'].decode('utf-8'), r)

if __name__ == "__main__":
    main()