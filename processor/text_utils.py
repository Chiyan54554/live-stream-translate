"""
æ–‡å­—è™•ç†æ¨¡çµ„ - éæ¿¾ã€å»é‡ã€æ¸…ç†
"""
import re
import sys
from collections import Counter


def calculate_similarity(s1: str, s2: str) -> float:
    """è¨ˆç®—å…©å€‹å­—ä¸²çš„ç›¸ä¼¼åº¦ (0-1) - ä½¿ç”¨å¤šç¨®ç®—æ³•"""
    if not s1 or not s2:
        return 0.0
    if s1 == s2:
        return 1.0
    
    # æ–¹æ³• 1: å­å­—ä¸²æª¢æ¸¬
    if s1 in s2 or s2 in s1:
        shorter = min(len(s1), len(s2))
        longer = max(len(s1), len(s2))
        return shorter / longer
    
    # æ–¹æ³• 2: N-gram ç›¸ä¼¼åº¦
    def get_ngrams(s, n=2):
        return set(s[i:i+n] for i in range(len(s)-n+1)) if len(s) >= n else {s}
    
    ngrams1 = get_ngrams(s1, 2)
    ngrams2 = get_ngrams(s2, 2)
    
    if not ngrams1 or not ngrams2:
        set1 = set(s1)
        set2 = set(s2)
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        return intersection / union if union > 0 else 0.0
    
    intersection = len(ngrams1 & ngrams2)
    union = len(ngrams1 | ngrams2)
    
    return intersection / union if union > 0 else 0.0


def remove_inline_repetition(text: str) -> str:
    """ç§»é™¤å¥ä¸­é€£çºŒé‡è¤‡çš„ç‰‡æ®µï¼ˆå¦‚ï¼šé€™ä»£ç¢¼ä¸éŒ¯é€™ä»£ç¢¼ä¸éŒ¯ï¼‰"""
    if not text or len(text) < 8:
        return text
    
    original = text
    
    # æ–¹æ³• 1: åµæ¸¬å®Œå…¨ç›¸åŒçš„é€£çºŒé‡è¤‡
    for pattern_len in range(min(25, len(text) // 2), 3, -1):
        for start in range(len(text) - pattern_len * 2 + 1):
            pattern = text[start:start + pattern_len]
            
            if all(c in 'ï¼Œã€‚ï¼ï¼Ÿã€ ï½~' for c in pattern):
                continue
            
            repeat_pos = start + pattern_len
            if text[repeat_pos:repeat_pos + pattern_len] == pattern:
                count = 2
                check_pos = repeat_pos + pattern_len
                while text[check_pos:check_pos + pattern_len] == pattern:
                    count += 1
                    check_pos += pattern_len
                
                prefix = text[:start]
                suffix = text[start + pattern_len * count:]
                result = (prefix + pattern + suffix).strip()
                
                if result != original:
                    print(f"ğŸ”§ ç§»é™¤è¡Œå…§é‡è¤‡: {original[:40]} -> {result[:40]}", file=sys.stderr, flush=True)
                    return remove_inline_repetition(result)
    
    # æ–¹æ³• 2: åµæ¸¬éé€£çºŒé‡è¤‡
    for phrase_len in range(3, min(15, len(text) // 3)):
        for start in range(len(text) - phrase_len):
            phrase = text[start:start + phrase_len]
            if all(c in 'ï¼Œã€‚ï¼ï¼Ÿã€ ï½~' for c in phrase):
                continue
            
            count = text.count(phrase)
            if count >= 3:
                first_idx = text.find(phrase)
                result = text[:first_idx + phrase_len]
                remaining = text[first_idx + phrase_len:]
                remaining = remaining.replace(phrase, '')
                result = (result + remaining).strip()
                result = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿ]{2,}', 'ã€‚', result)
                
                if result != original and len(result) >= 4:
                    print(f"ğŸ”§ ç§»é™¤æ•£è½é‡è¤‡: {original[:40]} -> {result[:40]}", file=sys.stderr, flush=True)
                    return result
    
    return text


def remove_repeated_substrings(text: str) -> str:
    """ç§»é™¤é€£çºŒé‡è¤‡çš„å­å­—ä¸² - ä¿ç•™ä¸é‡è¤‡çš„å‰ç¶´"""
    if len(text) < 8:
        return text
    
    # æŒ‰å¥å°¾æ¨™é»åˆ†å‰²
    sentence_endings = ['ã€‚', 'ï¼', 'ï¼Ÿ', '!', '?']
    for ending in sentence_endings:
        if ending in text:
            parts = []
            current = ""
            for char in text:
                current += char
                if char == ending:
                    if current.strip():
                        parts.append(current.strip())
                    current = ""
            if current.strip():
                parts.append(current.strip())
            
            if len(parts) >= 2:
                unique = []
                seen = set()
                for p in parts:
                    if p not in seen:
                        unique.append(p)
                        seen.add(p)
                
                if len(unique) < len(parts):
                    return ''.join(unique)
    
    # åµæ¸¬é€£çºŒé‡è¤‡çš„å­å­—ä¸²æ¨¡å¼
    for pattern_len in range(min(30, len(text) // 2), 4, -1):
        for start in range(len(text) - pattern_len * 2 + 1):
            pattern = text[start:start + pattern_len]
            
            if all(c in 'ï¼Œã€‚ï¼ï¼Ÿ ã€,.!? ' for c in pattern):
                continue
            
            has_ending = any(pattern.endswith(e) for e in ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼Œ', '!', '?', ','])
            if not has_ending:
                continue
            
            count = 0
            pos = 0
            first_idx = -1
            while True:
                idx = text.find(pattern, pos)
                if idx == -1:
                    break
                if first_idx == -1:
                    first_idx = idx
                count += 1
                pos = idx + len(pattern)
            
            if count >= 2 and len(pattern) * count > len(text) * 0.5:
                prefix = text[:first_idx].strip() if first_idx > 0 else ""
                result = pattern.strip()
                if prefix:
                    return prefix + result
                return result
    
    return text


def filter_translated_repetition(text: str) -> str:
    """éæ¿¾ç¿»è­¯å¾Œçš„é‡è¤‡å…§å®¹ - åŠ å¼·ç‰ˆ"""
    if not text or len(text) < 4:
        return text
    
    original_text = text
    
    # å…ˆç”¨ remove_inline_repetition è™•ç†
    text = remove_inline_repetition(text)
    if text != original_text:
        original_text = text
    
    # åµæ¸¬ç©ºæ ¼åˆ†éš”çš„å®Œå…¨ç›¸åŒç‰‡æ®µ
    if ' ' in text:
        space_parts = [p.strip() for p in text.split(' ') if p.strip()]
        if len(space_parts) >= 2:
            unique_space = []
            for p in space_parts:
                if not unique_space or p != unique_space[-1]:
                    is_dup = False
                    for u in unique_space:
                        if p == u or calculate_similarity(p, u) > 0.7:
                            is_dup = True
                            break
                    if not is_dup:
                        unique_space.append(p)
            
            if len(unique_space) < len(space_parts):
                result = ' '.join(unique_space)
                print(f"ğŸ”§ å»é™¤ç©ºæ ¼é‡è¤‡: {original_text[:40]} -> {result[:40]}", file=sys.stderr, flush=True)
                text = result
                original_text = result
    
    # åµæ¸¬é€£çºŒé‡è¤‡çš„å­å­—ä¸²
    cleaned = remove_repeated_substrings(text)
    if cleaned != text:
        print(f"ğŸ”§ å»é™¤é‡è¤‡å­å­—ä¸²: {original_text[:40]} -> {cleaned[:40]}", file=sys.stderr, flush=True)
        return cleaned
    
    # æŒ‰æ¨™é»åˆ†å‰²ä¸¦å»é‡
    separators = ['ï¼Œ', 'ã€‚', 'ï¼', 'ï¼Ÿ']
    for sep in separators:
        if sep in text and text.count(sep) >= 1:
            parts = [p.strip() for p in text.split(sep) if p.strip()]
            if len(parts) >= 2:
                unique = []
                for p in parts:
                    is_dup = False
                    for u in unique:
                        if p == u or calculate_similarity(p, u) > 0.6:
                            is_dup = True
                            break
                    if not is_dup:
                        unique.append(p)
                
                if len(unique) < len(parts):
                    result = sep.join(unique)
                    if sep in ['ã€‚', 'ï¼', 'ï¼Ÿ']:
                        result = result + sep if not result.endswith(sep) else result
                    print(f"ğŸ”§ å»é™¤ç¿»è­¯é‡è¤‡: {original_text[:40]} -> {result[:40]}", file=sys.stderr, flush=True)
                    return result
    
    return text


def detect_character_repetition(text: str) -> bool:
    """åµæ¸¬ç•°å¸¸çš„å­—ç¬¦é‡è¤‡ (å¹»è¦ºç‰¹å¾µ)"""
    if len(text) < 6:
        return False
    
    valid_patterns = ['ww', 'ãƒ¼ãƒ¼', '...', 'ï¼ï¼', 'ï¼Ÿï¼Ÿ', 'ã€œã€œ']
    temp_text = text
    for vp in valid_patterns:
        temp_text = temp_text.replace(vp, '')
    
    if len(temp_text) < 4:
        return False
    
    content_chars = [c for c in temp_text if c not in ' ã€€ã€ã€‚ï¼ï¼Ÿï¼Œ']
    if len(content_chars) < 4:
        return False
    
    char_counts = Counter(content_chars)
    max_count = max(char_counts.values())
    
    if max_count > len(content_chars) * 0.35:
        return True
    
    for pattern_len in range(2, min(15, len(text) // 3 + 1)):
        for start in range(min(3, len(text) - pattern_len * 3)):
            pattern = text[start:start + pattern_len]
            if all(c in 'ã€ï¼Œã€‚ï¼ï¼Ÿã€€ ãƒ»' for c in pattern):
                continue
            if pattern * 3 in text:
                return True
    
    return False


def detect_phrase_repetition(text: str) -> bool:
    """åµæ¸¬é‡è¤‡çš„è©çµ„"""
    for pattern_len in range(2, min(20, len(text) // 2 + 1)):
        for start in range(len(text) - pattern_len * 2 + 1):
            pattern = text[start:start + pattern_len]
            if all(c in 'ã€ï¼Œã€‚ï¼ï¼Ÿã€€ ' for c in pattern):
                continue
            if pattern * 3 in text:
                return True
    
    separators = ['ã€', 'ï¼Œ', 'ã€‚', ' ']
    for sep in separators:
        if sep in text:
            parts = [p.strip() for p in text.split(sep) if p.strip() and len(p.strip()) >= 2]
            if len(parts) >= 3:
                consecutive = 1
                for i in range(1, len(parts)):
                    if parts[i] == parts[i-1]:
                        consecutive += 1
                        if consecutive >= 2:
                            return True
                    else:
                        consecutive = 1
                
                counts = Counter(parts)
                for part, count in counts.items():
                    if count >= 2 and count >= len(parts) * 0.4:
                        return True
    
    return False


def remove_source_repetition(text: str) -> str:
    """å¾æ—¥æ–‡æºæ–‡ä¸­å»é™¤é‡è¤‡ï¼Œä¿ç•™æœ‰æ„ç¾©çš„å…§å®¹"""
    if not text or len(text) < 4:
        return text
    
    # æŒ‰ç©ºæ ¼åˆ†å‰²å»é‡
    if ' ' in text:
        parts = text.split(' ')
        unique = []
        seen = set()
        for p in parts:
            p = p.strip()
            if p and p not in seen:
                unique.append(p)
                seen.add(p)
        if len(unique) < len(parts):
            text = ' '.join(unique)
    
    # å°‹æ‰¾é‡è¤‡æ¨¡å¼ä¸¦åªä¿ç•™ä¸€æ¬¡
    for pattern_len in range(2, min(30, len(text) // 2 + 1)):
        for start in range(min(5, len(text) - pattern_len * 2)):
            pattern = text[start:start + pattern_len]
            
            if all(c in 'ã€ï¼Œã€‚ï¼ï¼Ÿã€€ ãƒ»ãƒ¼' for c in pattern):
                continue
            
            count = text.count(pattern)
            
            if count >= 3 and len(pattern) * count > len(text) * 0.4:
                first_idx = text.find(pattern)
                last_idx = text.rfind(pattern)
                
                prefix = text[:first_idx].strip() if first_idx > 0 else ""
                suffix = text[last_idx + len(pattern):].strip() if last_idx + len(pattern) < len(text) else ""
                
                result = prefix + pattern + suffix
                result = result.strip()
                
                if result and len(result) >= 2:
                    return result
    
    # å¦‚æœæ•´å€‹æ–‡å­—åªæ˜¯å–®ä¸€æ¨¡å¼é‡è¤‡
    for pattern_len in range(2, min(20, len(text) // 3 + 1)):
        pattern = text[:pattern_len]
        if all(c in 'ã€ï¼Œã€‚ï¼ï¼Ÿã€€ ãƒ»ãƒ¼' for c in pattern):
            continue
        
        repeated = pattern * (len(text) // len(pattern) + 1)
        if text in repeated or repeated.startswith(text):
            return pattern.strip()
    
    return text


def filter_text(text: str) -> str:
    """éæ¿¾ç„¡æ•ˆæ–‡å­—ï¼Œå»é™¤é‡è¤‡å¾Œä¿ç•™æœ‰æ•ˆå…§å®¹ç¹¼çºŒè™•ç†"""
    if not text:
        return ""
    
    # æ—¥æ–‡å­—ç¬¦éæ¿¾
    pattern = re.compile(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF\uFF00-\uFFEF\u0020-\u007E]+')
    cleaned = "".join(pattern.findall(text)).strip()
    
    if not cleaned:
        return ""
    
    # å¹»è¦ºéæ¿¾åˆ—è¡¨
    unwanted = [
        "[éŸ³å£°ãªã—]", "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†", "æœ€å¾Œã¾ã§ã”è¦–è´",
        "(æ‹æ‰‹)", "(ç¬‘ã„)", "(ãŸã‚æ¯)", "å­—å¹•",
        "ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²", "é«˜è©•ä¾¡", "MBSãƒ‹ãƒ¥ãƒ¼ã‚¹",
        "æä¾›ã¯", "ã”è¦§ã„ãŸã ã", "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ",
        "ãŠç–²ã‚Œæ§˜ã§ã—ãŸ", "ã¾ãŸä¼šã„ã¾ã—ã‚‡ã†", "ãƒã‚¤ãƒã‚¤",
        "æ¬¡å›ã‚‚", "ãƒãƒ£ãƒ³ãƒãƒ«", "ç™»éŒ²", "ãŠé¡˜ã„ã—ã¾ã™",
        "â™ª", "BGM", "éŸ³æ¥½", "ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°",
        "ãƒ†ãƒ­ãƒƒãƒ—", "ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", "ã‚¢ãƒŠã‚¦ãƒ³ã‚¹",
        "è©±ã—è¨€è‘‰", "ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªè¡¨ç¾", "ãƒãƒƒãƒˆã‚¹ãƒ©ãƒ³ã‚°",
        "VTuberé…ä¿¡", "é…ä¿¡è€…ã¨ãƒªã‚¹ãƒŠãƒ¼", "æ—¥æœ¬èªã®",
        "ç¿»è¨³", "å­—å¹•æä¾›", "è‡ªå‹•ç”Ÿæˆ", "æ©Ÿæ¢°ç¿»è¨³",
        "ç¶šãã¯", "è©³ã—ãã¯", "ãƒªãƒ³ã‚¯ã¯",
        "æ¦‚è¦æ¬„", "èª¬æ˜æ¬„", "ã‚³ãƒ¡ãƒ³ãƒˆæ¬„",
    ]
    
    for phrase in unwanted:
        if phrase in cleaned:
            return ""
    
    # å»é™¤é‡è¤‡å­—ç¬¦
    if detect_character_repetition(cleaned):
        deduped = remove_source_repetition(cleaned)
        if deduped and len(deduped) >= 2:
            print(f"ğŸ”„ å»é™¤æºæ–‡é‡è¤‡: {cleaned[:30]}... -> {deduped[:30]}", file=sys.stderr, flush=True)
            cleaned = deduped
        else:
            print(f"âš ï¸ éæ¿¾ç´”é‡è¤‡: {cleaned[:30]}...", file=sys.stderr, flush=True)
            return ""
    
    # å»é™¤é‡è¤‡è©çµ„
    if detect_phrase_repetition(cleaned):
        deduped = remove_source_repetition(cleaned)
        if deduped and len(deduped) >= 2:
            print(f"ğŸ”„ å»é™¤æºæ–‡é‡è¤‡: {cleaned[:30]}... -> {deduped[:30]}", file=sys.stderr, flush=True)
            cleaned = deduped
        else:
            print(f"âš ï¸ éæ¿¾ç´”é‡è¤‡: {cleaned[:30]}...", file=sys.stderr, flush=True)
            return ""
    
    return cleaned if len(cleaned) >= 2 else ""


def is_sentence_complete(text: str) -> bool:
    """æª¢æŸ¥æ–‡å­—æ˜¯å¦ç‚ºå®Œæ•´å¥å­"""
    if not text:
        return False
    
    sentence_endings = [
        'ã€‚', 'ï¼', 'ï¼Ÿ', 'ã€',
        'ã­', 'ã‚ˆ', 'ã‚ˆã­', 'ã‚', 'ã‹',
        'ã§ã™', 'ã¾ã™', 'ãŸ', 'ã ',
        'ã„', 'ã„ã‚ˆ', 'ã„ã­',
        '...', 'â€¦',
    ]
    
    text = text.strip()
    for ending in sentence_endings:
        if text.endswith(ending):
            return True
    
    if len(text) >= 15:
        return True
    
    return False


def merge_incomplete_sentence(pending: str, new_text: str) -> tuple:
    """åˆä½µä¸å®Œæ•´çš„å¥å­ï¼Œè¿”å› (å®Œæ•´å¥å­, å‰©é¤˜å¾…è™•ç†)"""
    if not pending:
        combined = new_text
    else:
        combined = pending + new_text
    
    if is_sentence_complete(combined):
        return combined, ""
    else:
        return "", combined


def extract_new_content(current: str, previous: str) -> str:
    """æå–æ–°å…§å®¹ï¼Œç§»é™¤èˆ‡å‰ä¸€æ¬¡é‡ç–Šçš„éƒ¨åˆ†"""
    if not previous or not current:
        return current
    
    if current == previous:
        return ""
    
    if previous in current:
        idx = current.find(previous)
        if idx == 0:
            return current[len(previous):].strip()
        elif idx + len(previous) == len(current):
            return current[:idx].strip()
    
    for i in range(min(len(previous), len(current)), 0, -1):
        if previous[-i:] == current[:i]:
            new_part = current[i:].strip()
            if len(new_part) >= 2:
                return new_part
            return ""
    
    for i in range(min(len(previous), len(current)), 0, -1):
        if previous[:i] == current[-i:]:
            new_part = current[:-i].strip()
            if len(new_part) >= 2:
                return new_part
            return ""
    
    return current
