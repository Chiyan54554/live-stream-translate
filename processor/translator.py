"""
ç¿»è­¯æ¨¡çµ„ - LLM ç¿»è­¯èˆ‡æ–‡å­—è½‰æ›
ğŸš€ å„ªåŒ–ç‰ˆï¼šé ç·¨è­¯æ­£å‰‡ã€é«˜æ•ˆè³‡æ–™çµæ§‹ã€æ¸›å°‘é‡è¤‡é‹ç®—
"""
import re
import sys
import asyncio
import aiohttp
import time
import os

from config import (
    LLM_API_URL,
    LLM_MODEL,
    LLM_TIMEOUT,
    USE_CLOUD_TRANSLATION,
    CLOUD_TRANSLATE_PROJECT_ID,
    CLOUD_TRANSLATE_LOCATION,
    CLOUD_TRANSLATE_TIMEOUT,
    TARGET_LANG_CODE,
    SOURCE_LANG_CODE,
)

# ğŸš€ å…¨åŸŸç‹€æ…‹ï¼šè¿½è¹¤ LLM æ˜¯å¦å°±ç·’
_llm_ready = False
_llm_warmup_done = False
_translate_client = None
_translate_parent = None
_cloud_disabled = False  # é¿å…é‡è¤‡ 403 é€ æˆåˆ·å±

try:
    from google.cloud import translate
except Exception:
    translate = None

from text_utils import (
    remove_inline_repetition, 
    filter_translated_repetition, 
    clean_gibberish_from_translation,
    RE_REPEATED_WORDS,
    RE_STUTTERING,
    RE_J_PREFIX_HALLUCINATION
)

# ============================================================
# ğŸš€ é ç·¨è­¯æ­£å‰‡è¡¨é”å¼ï¼ˆæ¨¡çµ„è¼‰å…¥æ™‚åªç·¨è­¯ä¸€æ¬¡ï¼‰
# ============================================================

RE_ROMAJI = re.compile(r'^[a-z\s\-\']+$', re.IGNORECASE)
RE_RUSSIAN = re.compile(r'[Ğ°-ÑĞ-Ğ¯Ñ‘Ğ]+')
RE_NON_TARGET_LANG = re.compile(r'[\u0600-\u06FF\u0590-\u05FF\u0E00-\u0E7F\u0900-\u097F\uAC00-\uD7AF]+')
RE_BOPOMOFO = re.compile(r'[\u3100-\u312F]+')
RE_TRAILING_DIGITS = re.compile(r'[\s]*[0-9]+[\s]*$')
RE_HIRAGANA_KATAKANA = re.compile(r'[\u3040-\u309F\u30A0-\u30FF]')
RE_CHINESE_CHARS = re.compile(r'[\u4E00-\u9FFF]')
RE_CONSECUTIVE_KANA = re.compile(r'[\u3040-\u309F\u30A0-\u30FF]{3,}')
RE_KANJI_KANA_PUNCT = re.compile(r'[\u4E00-\u9FFF][\u3040-\u309F\u30A0-\u30FF]+[ï¼Ÿï¼ã€‚]?')
RE_PURE_ENGLISH = re.compile(r'^[a-zA-Z_\s]+$')
RE_ENGLISH_WORD = re.compile(r'\b[a-zA-Z_]{4,}\b')
RE_MULTI_SPACE = re.compile(r'\s+')
RE_MARKDOWN_BOLD = re.compile(r'\*\*(.+?)\*\*')
RE_MARKDOWN_UNDERLINE = re.compile(r'__(.+?)__')
RE_MARKDOWN_CODE = re.compile(r'`(.+?)`')

# ğŸ¯ ä½å“è³ªç¿»è­¯éæ¿¾ï¼ˆèªæ„ä¸é€šé †æ¨¡å¼ï¼‰
RE_NONSENSE_PATTERN = re.compile(r'(.{1,2})\1{4,}')  # é€£çºŒé‡è¤‡ 1-2 å­— 5 æ¬¡ä»¥ä¸Š
RE_INCOMPLETE_ENDING = re.compile(r'[çš„åœ¨æ˜¯äº†å’Œè¦]$')  # ä¸å®Œæ•´çµå°¾

# ç¬¦è™Ÿæ¸…ç†ï¼ˆé ç·¨è­¯åˆ—è¡¨ï¼‰
RE_SYMBOL_CLEANUP = (
    (re.compile(r'[,\s]*[}\]]\s*'), ''),
    (re.compile(r'[:\s]*[)\]>]+\s*[?\s]*$'), ''),
    (re.compile(r'^[,\s]*[{\[]\s*'), ''),
    (re.compile(r'[!?]*["\';)]+\s*$'), ''),
    (re.compile(r'["\';(]+\s*[!?]*\s*$'), ''),
    (re.compile(r'\s*[!]{2,}["\');\s]*$'), ''),
    (re.compile(r'çš„["\'\s.ã€‚ï¼Œ,]+$'), 'çš„'),
    (re.compile(r'ä½ é€™[.\s]*$'), 'ä½ é€™å‚¢ä¼™'),
    (re.compile(r'[.\s]+$'), ''),
    (re.compile(r'^[-=_*#]+\s*'), ''),
    (re.compile(r'\s*[-=_*#]+$'), ''),
)

# ============================================================
# ğŸš€ é«˜æ•ˆè³‡æ–™çµæ§‹ï¼ˆfrozenset O(1) æŸ¥æ‰¾ï¼‰
# ============================================================

ALLOWED_ENGLISH_UPPER = frozenset({
    'K', 'KO', 'OK', 'COMBO', 'GAUGE', 'GUARD', 'ATTACK', 'WIN',
    'LOSE', 'HP', 'MP', 'SP', 'BGM', 'NG', 'GG', 'VS', 'DLC',
    'ONLINE', 'OFFLINE', 'S', 'A', 'B', 'C', 'D'
})

PREFIXES_TO_REMOVE = (
    'ç¿»è­¯ï¼š', 'ç¿»è­¯:', 'ä¸­æ–‡ï¼š', 'ä¸­æ–‡:', 'ç­”ï¼š', 'ç­”:',
    'ç¹é«”ä¸­æ–‡ï¼š', 'ç¹é«”ä¸­æ–‡:', 'è­¯æ–‡ï¼š', 'è­¯æ–‡:', 'å›ç­”ï¼š', 'å›ç­”:'
)

QUOTE_PAIRS = (
    ('"', '"'), ('ã€Œ', 'ã€'), ('ã€', 'ã€'), ("'", "'"),
)

# ============================================================
# ğŸš€ è½‰æ›è¡¨è¼‰å…¥èˆ‡é è™•ç†
# ============================================================

def _load_mapping(filename: str, description: str) -> dict:
    """å¾æª”æ¡ˆè¼‰å…¥æ˜ å°„è¡¨"""
    mapping = {}
    txt_path = os.path.join(os.path.dirname(__file__), 'mappings', filename)
    try:
        with open(txt_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                if '=' in line:
                    parts = line.split('=', 1)
                    if len(parts) == 2:
                        key, value = parts[0].strip(), parts[1].strip()
                        if key and value:
                            mapping[key] = value
        print(f"âœ… è¼‰å…¥{description}: {len(mapping)} çµ„", file=sys.stderr, flush=True)
    except FileNotFoundError:
        print(f"âš ï¸ æ‰¾ä¸åˆ°{description}: {txt_path}", file=sys.stderr, flush=True)
    except Exception as e:
        print(f"âš ï¸ è¼‰å…¥{description}å¤±æ•—: {e}", file=sys.stderr, flush=True)
    return mapping

# === OpenCC ç°¡ç¹è½‰æ›å™¨ ===
try:
    import opencc
    OPENCC_CONVERTER = opencc.OpenCC('s2twp')
    print(f"âœ… OpenCC ç°¡ç¹è½‰æ›å™¨å·²è¼‰å…¥ (s2twp)", file=sys.stderr, flush=True)
except ImportError:
    OPENCC_CONVERTER = None
    print(f"âš ï¸ OpenCC æœªå®‰è£ï¼Œå°‡ä½¿ç”¨å‚™ç”¨ txt å­—å…¸", file=sys.stderr, flush=True)

# è¼‰å…¥ä¸¦é æ’åºè½‰æ›è¡¨ï¼ˆåªæ’åºä¸€æ¬¡ï¼‰
_s2t_raw = _load_mapping('simplified_to_traditional.txt', 'ç°¡ç¹è½‰æ›è¡¨') if not OPENCC_CONVERTER else {}
_c2t_raw = _load_mapping('china_to_taiwan.txt', 'ä¸­å°ç”¨èªè¡¨')

SIMPLIFIED_TO_TRADITIONAL_SORTED = tuple(
    sorted(_s2t_raw.items(), key=lambda x: len(x[0]), reverse=True)
) if _s2t_raw else ()

CHINA_TO_TAIWAN_SORTED = tuple(
    sorted(_c2t_raw.items(), key=lambda x: len(x[0]), reverse=True)
)


async def warmup_llm():
    """ğŸš€ éé˜»å¡ LLM é ç†± - èƒŒæ™¯ç­‰å¾… Ollama å°±ç·’"""
    global _llm_ready, _llm_warmup_done

    if _llm_warmup_done:
        return _llm_ready

    if USE_CLOUD_TRANSLATION:
        _llm_ready = True
        _llm_warmup_done = True
        print("ğŸŒ ä½¿ç”¨ Cloud Translationï¼Œè·³é LLM é ç†±", file=sys.stderr, flush=True)
        return True

    async def _ensure_llm_model(session: aiohttp.ClientSession) -> bool:
        """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼›ä¸å­˜åœ¨æ™‚è§¸ç™¼æ‹‰å–ä»¥é¿å… 404"""
        try:
            async with session.post(
                f"{LLM_API_URL.replace('/api/generate','')}/api/show",
                json={"model": LLM_MODEL},
                timeout=aiohttp.ClientTimeout(total=10)
            ) as resp:
                if resp.status == 200:
                    return True
                if resp.status != 404:
                    print(f"âš ï¸ æ¨¡å‹æª¢æŸ¥å¤±æ•—: HTTP {resp.status}", file=sys.stderr, flush=True)
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹æª¢æŸ¥éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
            # ç¹¼çºŒå˜—è©¦æ‹‰å–
        # å˜—è©¦æ‹‰å–æ¨¡å‹
        print(f"ğŸ”„ è‡ªå‹•æ‹‰å–æ¨¡å‹ {LLM_MODEL} ...", file=sys.stderr, flush=True)
        try:
            async with session.post(
                f"{LLM_API_URL.replace('/api/generate','')}/api/pull",
                json={"model": LLM_MODEL, "stream": False},
                timeout=aiohttp.ClientTimeout(total=900)
            ) as resp:
                if resp.status == 200:
                    print(f"âœ… å·²æ‹‰å–æ¨¡å‹ {LLM_MODEL}", file=sys.stderr, flush=True)
                    return True
                else:
                    print(f"âš ï¸ æ‹‰å–æ¨¡å‹å¤±æ•—: HTTP {resp.status}", file=sys.stderr, flush=True)
                    return False
        except Exception as e:
            print(f"âš ï¸ æ‹‰å–æ¨¡å‹éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
            return False

    print("ğŸ”„ èƒŒæ™¯ç­‰å¾… Ollama æ¨¡å‹è¼‰å…¥...", file=sys.stderr, flush=True)
    start_time = time.time()
    max_wait = 300  # æœ€å¤šç­‰å¾… 5 åˆ†é˜ï¼ˆé¦–æ¬¡è¼‰å…¥æ¨¡å‹åˆ° GPU éœ€è¦æ™‚é–“ï¼‰
    
    async with aiohttp.ClientSession() as session:
        model_ready = await _ensure_llm_model(session)
        if not model_ready:
            print("âš ï¸ æ¨¡å‹ä¸å­˜åœ¨ä¸”æ‹‰å–å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ¨¡å‹åç¨±æˆ–ç¶²è·¯", file=sys.stderr, flush=True)
            _llm_warmup_done = True
            _llm_ready = False
            return False

        while time.time() - start_time < max_wait:
            try:
                # ğŸš€ é¦–æ¬¡è«‹æ±‚éœ€è¦ 60 ç§’ä»¥ä¸Šï¼ˆæ¨¡å‹è¼‰å…¥åˆ° GPUï¼‰
                async with session.post(
                    LLM_API_URL,
                    json={
                        "model": LLM_MODEL,
                        "prompt": "ä½ å¥½",
                        "stream": False,
                        "think": False,
                        "options": {"num_predict": 5}
                    },
                    timeout=aiohttp.ClientTimeout(total=120)  # 120 ç§’è¶…æ™‚
                ) as response:
                    if response.status == 200:
                        elapsed = time.time() - start_time
                        print(f"âœ… LLM å°±ç·’ï¼(è¼‰å…¥è€—æ™‚ {elapsed:.1f}s)", file=sys.stderr, flush=True)
                        _llm_ready = True
                        _llm_warmup_done = True
                        return True
                    elif response.status == 499:
                        # 499 = è«‹æ±‚è¢«å–æ¶ˆï¼ˆæ¨¡å‹æ­£åœ¨è¼‰å…¥ï¼‰
                        print(f"â³ æ¨¡å‹è¼‰å…¥ä¸­... ({time.time() - start_time:.0f}s)", file=sys.stderr, flush=True)
                        await asyncio.sleep(5)
                    else:
                        print(f"âš ï¸ LLM å›æ‡‰: {response.status}", file=sys.stderr, flush=True)
                        await asyncio.sleep(5)
            except asyncio.TimeoutError:
                print(f"â³ ç­‰å¾…æ¨¡å‹è¼‰å…¥... ({time.time() - start_time:.0f}s)", file=sys.stderr, flush=True)
                await asyncio.sleep(3)
            except aiohttp.ClientError:
                # Ollama æœå‹™é‚„æ²’å•Ÿå‹•
                await asyncio.sleep(3)
            except Exception as e:
                print(f"âš ï¸ é ç†±éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
                await asyncio.sleep(5)
        
        print("âš ï¸ LLM é ç†±è¶…æ™‚ï¼Œç¿»è­¯åŠŸèƒ½å¯èƒ½å—å½±éŸ¿", file=sys.stderr, flush=True)
        _llm_warmup_done = True
        # å³ä½¿è¶…æ™‚ä¹Ÿæ¨™è¨˜ç‚ºå°±ç·’ï¼Œè®“ç¿»è­¯å¯ä»¥å˜—è©¦
        _llm_ready = True
        return False


def is_llm_ready() -> bool:
    """æª¢æŸ¥ LLM æ˜¯å¦å·²å°±ç·’"""
    return _llm_ready


# ============================================================
# ğŸš€ å„ªåŒ–ç‰ˆæ¸…ç†å‡½æ•¸
# ============================================================

def _clean_english_word(match) -> str:
    """æ¸…ç†è‹±æ–‡è©ï¼ˆO(1) frozenset æŸ¥æ‰¾ï¼‰"""
    word = match.group(0)
    if word.upper() in ALLOWED_ENGLISH_UPPER or len(word) <= 2:
        return word
    return ''


def clean_llm_output(text: str) -> str:
    """æ¸…ç† LLM è¼¸å‡º - å„ªåŒ–ç‰ˆï¼ˆé ç·¨è­¯æ­£å‰‡ + é«˜æ•ˆè³‡æ–™çµæ§‹ï¼‰"""
    if not text:
        return ""
    
    text_stripped = text.strip()
    
    # 1. éæ¿¾ç¾…é¦¬æ‹¼éŸ³
    if RE_ROMAJI.match(text_stripped) and len(text) > 10:
        print(f"âš ï¸ éæ¿¾ç¾…é¦¬æ‹¼éŸ³: {text[:40]}", file=sys.stderr, flush=True)
        return ""
    
    # 2. ç§»é™¤éç›®æ¨™èªè¨€å­—ç¬¦
    if RE_RUSSIAN.search(text):
        text = RE_RUSSIAN.sub('', text)
        print(f"âš ï¸ ç§»é™¤ä¿„æ–‡å­—ç¬¦", file=sys.stderr, flush=True)
    
    if RE_NON_TARGET_LANG.search(text):
        text = RE_NON_TARGET_LANG.sub('', text)
        print(f"âš ï¸ ç§»é™¤éç›®æ¨™èªè¨€å­—ç¬¦", file=sys.stderr, flush=True)
    
    if RE_BOPOMOFO.search(text):
        text = RE_BOPOMOFO.sub('', text)
        print(f"âš ï¸ ç§»é™¤æ³¨éŸ³ç¬¦è™Ÿ", file=sys.stderr, flush=True)
    
    text = RE_TRAILING_DIGITS.sub('', text)
    
    # 3. æ—¥æ–‡å‡åéæ¿¾
    hiragana_katakana = len(RE_HIRAGANA_KATAKANA.findall(text))
    chinese_chars = len(RE_CHINESE_CHARS.findall(text))
    
    if hiragana_katakana > chinese_chars and hiragana_katakana > 5:
        print(f"âš ï¸ éæ¿¾æœªç¿»è­¯æ—¥æ–‡: {text[:40]}", file=sys.stderr, flush=True)
        return ""
    
    def _clean_kana_fragment(match):
        fragment = match.group(0)
        if len(fragment) <= 2:
            return fragment
        print(f"âš ï¸ ç§»é™¤æ—¥æ–‡ç‰‡æ®µ: {fragment}", file=sys.stderr, flush=True)
        return ''
    
    text = RE_CONSECUTIVE_KANA.sub(_clean_kana_fragment, text)
    
    def _clean_kanji_kana(match):
        m_text = match.group(0)
        if len(RE_HIRAGANA_KATAKANA.findall(m_text)) >= 2:
            return ''
        return m_text
    
    text = RE_KANJI_KANA_PUNCT.sub(_clean_kanji_kana, text)
    
    # 4. éæ¿¾ç´”è‹±æ–‡
    if RE_PURE_ENGLISH.match(text.strip()) and len(text) > 5:
        print(f"âš ï¸ éæ¿¾ç´”è‹±æ–‡: {text[:40]}", file=sys.stderr, flush=True)
        return ""
    
    # 5. ç§»é™¤å‰ç¶´ï¼ˆtuple è¿­ä»£ï¼‰
    for prefix in PREFIXES_TO_REMOVE:
        if text.startswith(prefix):
            text = text[len(prefix):].strip()
            break
    
    # 6. ç§»é™¤å¼•è™ŸåŒ…è£¹
    if len(text) >= 2:
        for open_q, close_q in QUOTE_PAIRS:
            if text[0] == open_q and text[-1] == close_q:
                text = text[1:-1].strip()
                break
    
    # 7. æ‰¹æ¬¡ç¬¦è™Ÿæ¸…ç†
    for pattern, replacement in RE_SYMBOL_CLEANUP:
        text = pattern.sub(replacement, text)
    
    # 8. ç§»é™¤ Markdown
    text = RE_MARKDOWN_BOLD.sub(r'\1', text)
    text = RE_MARKDOWN_UNDERLINE.sub(r'\1', text)
    text = RE_MARKDOWN_CODE.sub(r'\1', text)
    
    # 9. ç§»é™¤ç•°å¸¸è‹±æ–‡
    text = RE_ENGLISH_WORD.sub(_clean_english_word, text)
    
    # 10. æ¸…ç†é€£çºŒé‡è¤‡
    text = remove_inline_repetition(text)
    
    # 11. ç°¡é«”è½‰ç¹é«”
    if OPENCC_CONVERTER:
        try:
            text = OPENCC_CONVERTER.convert(text)
        except Exception as e:
            print(f"âš ï¸ OpenCC è½‰æ›å¤±æ•—: {e}", file=sys.stderr, flush=True)
            for simp, trad in SIMPLIFIED_TO_TRADITIONAL_SORTED:
                text = text.replace(simp, trad)
    elif SIMPLIFIED_TO_TRADITIONAL_SORTED:
        for simp, trad in SIMPLIFIED_TO_TRADITIONAL_SORTED:
            text = text.replace(simp, trad)
    
    # 12. ä¸­åœ‹ç”¨èª â†’ å°ç£ç”¨èªï¼ˆé æ’åº tupleï¼‰
    for china, taiwan in CHINA_TO_TAIWAN_SORTED:
        text = text.replace(china, taiwan)
    
    # 13. ğŸ¯ éæ¿¾ä½å“è³ªç¿»è­¯
    # éæ¿¾ï¼šæ˜¯æƒ³è¦æ˜¯æƒ³è¦è¦å›ä¾†æƒ³è¦å‘¢å¤§éš»çš„
    if RE_REPEATED_WORDS.search(text):
        print(f"âš ï¸ éæ¿¾ä½å“è³ªç¿»è­¯ï¼ˆé‡è¤‡è©ï¼‰: {text[:40]}", file=sys.stderr, flush=True)
        return ""
    
    # éæ¿¾ï¼šå¿«å¿«é­”åŠ ä¸è¦ä¸è¦è¦ä¸è¦å•¦
    if RE_NONSENSE_PATTERN.search(text):
        match = RE_NONSENSE_PATTERN.search(text)
        pattern = match.group(1)
        # å˜—è©¦ä¿®å¾©ï¼šåªä¿ç•™ä¸€æ¬¡
        fixed = RE_NONSENSE_PATTERN.sub(pattern, text)
        if fixed != text and len(fixed) >= 4:
            print(f"ğŸ”§ ä¿®å¾©é‡è¤‡æ¨¡å¼: {text[:40]} -> {fixed[:40]}", file=sys.stderr, flush=True)
            text = fixed
        else:
            print(f"âš ï¸ éæ¿¾ç„¡æ„ç¾©é‡è¤‡: {text[:40]}", file=sys.stderr, flush=True)
            return ""
    
    # éæ¿¾ä¸å®Œæ•´çš„å¥å­ï¼ˆä½†ä¸éæ¿¾å¤ªçŸ­çš„ï¼‰
    if len(text) >= 8 and RE_INCOMPLETE_ENDING.search(text):
        # å˜—è©¦ç§»é™¤ä¸å®Œæ•´çµå°¾
        cleaned = RE_INCOMPLETE_ENDING.sub('', text).strip()
        if len(cleaned) >= 4:
            print(f"ğŸ”§ ç§»é™¤ä¸å®Œæ•´çµå°¾: {text[:40]} -> {cleaned[:40]}", file=sys.stderr, flush=True)
            text = cleaned
    
    # 14. ç§»é™¤å¤šé¤˜ç©ºæ ¼
    text = RE_MULTI_SPACE.sub(' ', text).strip()
    
    return text


# ============================================================
# ğŸŒ Cloud Translation (Google)
# ============================================================

def _get_translate_client():
    """å»ºç«‹æˆ–å›å‚³å…±ç”¨çš„ Cloud Translation client"""
    global _translate_client, _translate_parent
    if _translate_client:
        return _translate_client
    if not translate:
        print("âš ï¸ æœªå®‰è£ google-cloud-translateï¼Œç„¡æ³•ä½¿ç”¨ Cloud Translation", file=sys.stderr, flush=True)
        return None
    if not CLOUD_TRANSLATE_PROJECT_ID:
        print("âš ï¸ æœªè¨­å®š CLOUD_TRANSLATE_PROJECT_IDï¼Œç„¡æ³•ä½¿ç”¨ Cloud Translation", file=sys.stderr, flush=True)
        return None
    if not re.match(r"^[a-z][a-z0-9-]*$", CLOUD_TRANSLATE_PROJECT_ID):
        print(f"âš ï¸ CLOUD_TRANSLATE_PROJECT_ID æ ¼å¼ç„¡æ•ˆ: {CLOUD_TRANSLATE_PROJECT_ID}", file=sys.stderr, flush=True)
        return None
    try:
        _translate_client = translate.TranslationServiceClient()
        _translate_parent = f"projects/{CLOUD_TRANSLATE_PROJECT_ID}/locations/{CLOUD_TRANSLATE_LOCATION}"
    except Exception as e:
        print(f"âš ï¸ å»ºç«‹ Cloud Translation client å¤±æ•—: {e}", file=sys.stderr, flush=True)
        _translate_client = None
    return _translate_client


def _cloud_translate_sync(text: str) -> str:
    global _cloud_disabled
    if _cloud_disabled:
        return ""
    client = _get_translate_client()
    if client is None:
        return ""
    if not _translate_parent:
        return ""
    try:
        response = client.translate_text(
            request={
                "parent": _translate_parent,
                "contents": [text],
                "mime_type": "text/plain",
                "source_language_code": SOURCE_LANG_CODE,
                "target_language_code": TARGET_LANG_CODE,
            },
            timeout=CLOUD_TRANSLATE_TIMEOUT,
        )
        if response.translations:
            return response.translations[0].translated_text
    except Exception as e:
        msg = str(e)
        print(f"âš ï¸ Cloud Translation å¤±æ•—: {msg}", file=sys.stderr, flush=True)
        if "cloudtranslate.generalModels.predict" in msg or "403" in msg:
            print("âš ï¸ åµæ¸¬åˆ°æ¬Šé™ä¸è¶³ï¼Œæš«åœ Cloud Translationï¼Œè«‹ç‚º service account åŠ ä¸Š Cloud Translation API User è§’è‰²", file=sys.stderr, flush=True)
            _cloud_disabled = True
    return ""


async def _translate_with_cloud(text: str) -> str:
    if not text:
        return ""
    loop = asyncio.get_event_loop()
    translated = await loop.run_in_executor(None, _cloud_translate_sync, text)
    if translated:
        translated = clean_llm_output(translated)
    if translated:
        translated = filter_translated_repetition(translated)
    if translated:
        translated = clean_gibberish_from_translation(translated)
    return translated


# ============================================================
# ğŸš€ LLM ç¿»è­¯ï¼ˆé å»ºç«‹æ¨¡æ¿ï¼‰
# ============================================================

_PROMPT_TEMPLATE = """ä½ æ˜¯å°ˆæ¥­çš„æ—¥æ–‡éŠæˆ²ç›´æ’­å³æ™‚ç¿»è­¯å“¡ã€‚è«‹å°‡ä»¥ä¸‹æ—¥æ–‡æº–ç¢ºç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰ã€‚

ç¿»è­¯è¦å‰‡ï¼š
1. åªè¼¸å‡ºç¿»è­¯çµæœï¼Œä¸è¦è§£é‡‹æˆ–è¨»è§£
2. ä¿æŒå£èªåŒ–ã€è‡ªç„¶çš„èªæ°£
3. äººåéŸ³è­¯ï¼šç”¨å¸¸è¦‹ä¸­æ–‡è­¯æ³•ï¼ˆå¦‚ãƒ’ãƒ­â†’é˜¿å»£ã€ã‚¿ã‚±ã‚·â†’é˜¿æ­¦ã€ã•ã‚“â†’æ¡‘/å…ˆç”Ÿï¼‰
4. éŠæˆ²è¡“èªï¼šä½¿ç”¨å°ç£ç©å®¶æ…£ç”¨è­¯æ³•
5. ç‰‡å‡åå¤–ä¾†èªï¼šç¿»æˆä¸­æ–‡æ„æ€ï¼Œä¸è¦éŸ³è­¯
6. èªæ°£è©ä¿ç•™è‡ªç„¶æ„Ÿï¼ˆå¦‚ï¼šå•Šã€å‘¢ã€å•¦ã€æ¬¸ï¼‰
7. è½ä¸æ¸…æˆ–ç„¡æ„ç¾©çš„è¼¸å…¥ï¼Œå›è¦†ç©ºç™½

æ—¥æ–‡ï¼š{text}
ä¸­æ–‡ï¼š"""

_REQUEST_OPTIONS = {
    "temperature": 0.2,
    "top_p": 0.85,
    "top_k": 30,
    "num_predict": 256,
    "repeat_penalty": 1.15,
    "stop": ["\n\n", "æ—¥æ–‡ï¼š", "æ—¥æ–‡åŸæ–‡", "ä¸­æ–‡ï¼š", "ç¿»è­¯ï¼š"]
}


async def llm_translate(text: str, session: aiohttp.ClientSession) -> str:
    """ä½¿ç”¨ Ollama Qwen3 LLM é€²è¡Œæ—¥æ–‡åˆ°ç¹é«”ä¸­æ–‡ç¿»è­¯"""
    if not text:
        return ""

    if USE_CLOUD_TRANSLATION and not _cloud_disabled:
        translated = await _translate_with_cloud(text)
        if translated:
            return translated
        print("âš ï¸ Cloud Translation å¤±æ•—ï¼Œæ”¹ç”¨ Ollama å‚™æ´", file=sys.stderr, flush=True)
    
    if not _llm_ready and not _llm_warmup_done:
        return ""
    
    prompt = _PROMPT_TEMPLATE.format(text=text)
    request_body = {
        "model": LLM_MODEL,
        "prompt": prompt,
        "stream": False,
        "think": False,
        "options": _REQUEST_OPTIONS
    }
    
    max_retries = 2
    retry_timeout = LLM_TIMEOUT
    
    for attempt in range(max_retries + 1):
        try:
            current_timeout = retry_timeout * 3 if attempt == 0 else retry_timeout
            
            async with session.post(
                LLM_API_URL,
                json=request_body,
                timeout=aiohttp.ClientTimeout(total=current_timeout)
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    translated = result.get('response', '').strip()
                    translated = clean_llm_output(translated)
                    if translated:
                        translated = filter_translated_repetition(translated)
                    if translated:
                        translated = clean_gibberish_from_translation(translated)
                    return translated
                else:
                    print(f"LLM ç¿»è­¯å¤±æ•—: HTTP {response.status}", file=sys.stderr, flush=True)
                    if attempt < max_retries:
                        await asyncio.sleep(0.5)
                        continue
                    return ""
                    
        except asyncio.TimeoutError:
            if attempt < max_retries:
                print(f"LLM è¶…æ™‚ï¼Œé‡è©¦ ({attempt + 1}/{max_retries})...", file=sys.stderr, flush=True)
                await asyncio.sleep(0.5)
                continue
            print(f"LLM ç¿»è­¯è¶…æ™‚ ({LLM_TIMEOUT}s)", file=sys.stderr, flush=True)
            return ""
        except aiohttp.ClientError as e:
            if attempt < max_retries:
                print(f"LLM é€£ç·šå¤±æ•—ï¼Œé‡è©¦ ({attempt + 1}/{max_retries})...", file=sys.stderr, flush=True)
                await asyncio.sleep(1)
                continue
            print(f"ç„¡æ³•é€£æ¥ LLM æœå‹™: {e}", file=sys.stderr, flush=True)
            return ""
        except Exception as e:
            print(f"LLM ç¿»è­¯éŒ¯èª¤: {e}", file=sys.stderr, flush=True)
            return ""
    
    return ""
